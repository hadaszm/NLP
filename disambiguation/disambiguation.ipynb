{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../big_data/'\n",
    "MAX_ITER = 7\n",
    "no_embedings = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeding(word,emb):\n",
    "    return emb.loc[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tags_list_dict(row):\n",
    "    # dictionary keyword: list of concepts\n",
    "    result = {}\n",
    "    for tag in row:\n",
    "        if tag[0] in result.keys():\n",
    "            if  tag[1] not in result[tag[0]]:\n",
    "                result[tag[0]].append(tag[1])\n",
    "        else:\n",
    "            result[tag[0]]= [tag[1]]\n",
    "\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguation(current_selection,embedings):\n",
    "    ''' \n",
    "    current_selection : dictionary keyword: list of all unique concepts\n",
    "    \n",
    "    '''\n",
    "    # we iterate over the current_selection MAX_ITER times\n",
    "    for i in range(MAX_ITER):\n",
    "        for keyword, concepts_list in current_selection.items():\n",
    "            distances = {} # for each possible concept calaculate the mean distance from other kewords (concepts of them)\n",
    "            for concept in concepts_list:\n",
    "                distances[concept] = []\n",
    "                for k, current_best_tags in current_selection.items():\n",
    "                    # foreach keyword that is not a current one \n",
    "                    if k!=keyword:\n",
    "                        current_best_tag = current_best_tags[0] # the first out of list of concepts\n",
    "                        try:\n",
    "                            distances[concept].append(math.dist(get_embeding(concept,embedings),get_embeding(current_best_tag,embedings))) # append distance from this concept\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                distances[concept] = np.mean(distances[concept]) # mean distance \n",
    "            current_selection[keyword] = sorted(distances, key=distances.get) # upadate the current selection of this keyword\n",
    "    return current_selection\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(folder,'bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_train.csv'))\n",
    "train['ncbo_annotations_pairs'] = train['ncbo_annotations_pairs'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedings_fine_tuned = pd.read_csv(os.path.join(folder,'bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_train_model_fine_tuned.csv'))\n",
    "embedings_fine_tuned = embedings_fine_tuned.set_index('words')\n",
    "\n",
    "embedings_fine_pretrained = pd.read_csv(os.path.join(folder,'bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_train_model_pretrained.csv'))\n",
    "embedings_fine_pretrained = embedings_fine_pretrained.set_index('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Metabolic Process</th>\n",
       "      <td>0.583000</td>\n",
       "      <td>-0.012395</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.376704</td>\n",
       "      <td>0.660073</td>\n",
       "      <td>0.438554</td>\n",
       "      <td>0.571691</td>\n",
       "      <td>0.231643</td>\n",
       "      <td>-0.742332</td>\n",
       "      <td>-0.904984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450005</td>\n",
       "      <td>-0.112175</td>\n",
       "      <td>0.501938</td>\n",
       "      <td>0.195895</td>\n",
       "      <td>0.017445</td>\n",
       "      <td>0.118989</td>\n",
       "      <td>-0.311507</td>\n",
       "      <td>-0.254814</td>\n",
       "      <td>-0.192918</td>\n",
       "      <td>-0.199149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obesity [Disease/Finding]</th>\n",
       "      <td>-0.123698</td>\n",
       "      <td>-0.108045</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>-0.415700</td>\n",
       "      <td>0.554280</td>\n",
       "      <td>0.058951</td>\n",
       "      <td>0.278378</td>\n",
       "      <td>0.431898</td>\n",
       "      <td>-0.240664</td>\n",
       "      <td>-0.126073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136707</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.070385</td>\n",
       "      <td>-0.229363</td>\n",
       "      <td>0.334851</td>\n",
       "      <td>0.287971</td>\n",
       "      <td>0.090172</td>\n",
       "      <td>-0.100504</td>\n",
       "      <td>-0.173628</td>\n",
       "      <td>-0.362540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVC group</th>\n",
       "      <td>0.666851</td>\n",
       "      <td>-0.378545</td>\n",
       "      <td>-0.242242</td>\n",
       "      <td>0.146456</td>\n",
       "      <td>0.470777</td>\n",
       "      <td>0.347311</td>\n",
       "      <td>-0.229048</td>\n",
       "      <td>0.309446</td>\n",
       "      <td>-0.451586</td>\n",
       "      <td>0.247780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>0.376668</td>\n",
       "      <td>0.559750</td>\n",
       "      <td>0.034041</td>\n",
       "      <td>0.508923</td>\n",
       "      <td>0.197937</td>\n",
       "      <td>-0.209565</td>\n",
       "      <td>0.010399</td>\n",
       "      <td>-0.212529</td>\n",
       "      <td>-0.341406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0         1         2         3         4  \\\n",
       "words                                                                         \n",
       "Metabolic Process          0.583000 -0.012395 -0.401520 -0.376704  0.660073   \n",
       "Obesity [Disease/Finding] -0.123698 -0.108045  0.094596 -0.415700  0.554280   \n",
       "PVC group                  0.666851 -0.378545 -0.242242  0.146456  0.470777   \n",
       "\n",
       "                                  5         6         7         8         9  \\\n",
       "words                                                                         \n",
       "Metabolic Process          0.438554  0.571691  0.231643 -0.742332 -0.904984   \n",
       "Obesity [Disease/Finding]  0.058951  0.278378  0.431898 -0.240664 -0.126073   \n",
       "PVC group                  0.347311 -0.229048  0.309446 -0.451586  0.247780   \n",
       "\n",
       "                           ...       758       759       760       761  \\\n",
       "words                      ...                                           \n",
       "Metabolic Process          ...  0.450005 -0.112175  0.501938  0.195895   \n",
       "Obesity [Disease/Finding]  ...  0.136707  0.001791  0.070385 -0.229363   \n",
       "PVC group                  ... -0.002421  0.376668  0.559750  0.034041   \n",
       "\n",
       "                                762       763       764       765       766  \\\n",
       "words                                                                         \n",
       "Metabolic Process          0.017445  0.118989 -0.311507 -0.254814 -0.192918   \n",
       "Obesity [Disease/Finding]  0.334851  0.287971  0.090172 -0.100504 -0.173628   \n",
       "PVC group                  0.508923  0.197937 -0.209565  0.010399 -0.212529   \n",
       "\n",
       "                                767  \n",
       "words                                \n",
       "Metabolic Process         -0.199149  \n",
       "Obesity [Disease/Finding] -0.362540  \n",
       "PVC group                 -0.341406  \n",
       "\n",
       "[3 rows x 768 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedings_fine_tuned.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_tags = train['ncbo_annotations_pairs'].apply(lambda r: create_tags_list_dict(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       {'CELL': ['Diagnostic, Therapeutic, or Researc...\n",
       "1       {'CELL': ['Diagnostic, Therapeutic, or Researc...\n",
       "2       {'CELL': ['Diagnostic, Therapeutic, or Researc...\n",
       "3       {'SPINE': ['Anatomical entity', 'Musculoskelet...\n",
       "4       {'PATIENT': ['Veterinary Patient', 'Person', '...\n",
       "                              ...                        \n",
       "3508    {'CELL': ['Diagnostic, Therapeutic, or Researc...\n",
       "3509    {'FOOD': ['Physical Object', 'Substance', 'Foo...\n",
       "3510    {'ECL': ['Clinical Pathology Procedure', 'Cyto...\n",
       "3511    {'ASTHMA': ['Asthma Pathway', 'Asthma', 'Lung ...\n",
       "3512    {'IMPLANT': ['Unit by Category', 'Implant Dosi...\n",
       "Name: ncbo_annotations_pairs, Length: 3513, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 131/3513 [04:28<2:28:05,  2.63s/it]c:\\Users\\gosia\\anaconda3\\envs\\envNNN\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\gosia\\anaconda3\\envs\\envNNN\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 3513/3513 [3:17:26<00:00,  3.37s/it]    \n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for current_selection in tqdm.tqdm(possible_tags):\n",
    "    res.append(disambiguation(current_selection, embedings_fine_tuned))\n",
    "train['after_disambiguation_fine_tuned'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for current_selection in tqdm.tqdm(possible_tags):\n",
    "    res.append(disambiguation(current_selection, embedings_fine_pretrained))\n",
    "train['after_disambiguation_pretrained'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(os.path.join(folder,'bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_train_disambiguation.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(folder,'bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_test.csv'))\n",
    "test['ncbo_annotations_pairs'] = test['ncbo_annotations_pairs'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedings_fine_tuned = pd.read_csv(os.path.join(folder,'bertopic_ncbo__fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_test_model_fine_tuned.csv'))\n",
    "embedings_fine_tuned = embedings_fine_tuned.set_index('words')\n",
    "\n",
    "embedings_fine_pretrained = pd.read_csv(os.path.join(folder,'bertopic_ncbo__fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_test_model_pretrained.csv'))\n",
    "embedings_fine_pretrained = embedings_fine_pretrained.set_index('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_tags = test['ncbo_annotations_pairs'].apply(lambda r: create_tags_list_dict(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for current_selection in tqdm.tqdm(possible_tags):\n",
    "    res.append(disambiguation(current_selection, embedings_fine_tuned))\n",
    "test['after_disambiguation_fine_tuned'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for current_selection in tqdm.tqdm(possible_tags):\n",
    "    res.append(disambiguation(current_selection, embedings_fine_pretrained))\n",
    "test['after_disambiguation_pretrained'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(os.path.join(folder,'bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_test_disambiguation.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('envNNN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69b1adaa11ceff177c5ff5a0e22271ae8b2837f309a3421a8d0197a8c1aada63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
