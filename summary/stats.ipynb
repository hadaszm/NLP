{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6186f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e95bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8391290",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_glob_regex = '../results/embeddings/concepts_embeddings_*_biobert.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec41667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(TP, FP): \n",
    "    return TP/(TP+FP)\n",
    "\n",
    "def recall(TP, FN): \n",
    "    return TP/(TP+FN)\n",
    "\n",
    "def F1(precision, recall):\n",
    "    return 2/(1/precision + 1/recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3c0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_TP_FN_FP(keywords, ground_truth):\n",
    "    keywords = set(keywords)\n",
    "    ground_truth = set(ground_truth)\n",
    "    TP = len(keywords.intersection(ground_truth) )\n",
    "    FN = len(keywords.difference(ground_truth))\n",
    "    FP = len(ground_truth.difference(keywords))\n",
    "    return np.array([TP, FN, FP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d33618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_list(pmid, pairs):\n",
    "    result = []\n",
    "    for pair in pairs:\n",
    "        result.append((pmid, pair[0], pair[1]))\n",
    "    return result\n",
    "\n",
    "def explode_df(df): \n",
    "    result = []\n",
    "    for i, row in df.iterrows(): \n",
    "        result += explode_list(row['PMID'], eval(row['ncbo_annotations_pairs']))\n",
    "    return pd.DataFrame(result, columns=['PMID', 'keyword', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e66a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>true_CUIs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25763772</td>\n",
       "      <td>[C4308010, C0854135, C0599755, C0026882, C0597...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25847295</td>\n",
       "      <td>[C0150312, C0229671, C0009968, C1383501, C0007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26316050</td>\n",
       "      <td>[C0005847, C0444498, C1708386, C0442069, C2828...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26406200</td>\n",
       "      <td>[C0231472, C0026845, C0277814, C1257890, C0224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26424709</td>\n",
       "      <td>[C0022558, C2939193, C0241311, C0018704, C0679...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                          true_CUIs\n",
       "0  25763772  [C4308010, C0854135, C0599755, C0026882, C0597...\n",
       "1  25847295  [C0150312, C0229671, C0009968, C1383501, C0007...\n",
       "2  26316050  [C0005847, C0444498, C1708386, C0442069, C2828...\n",
       "3  26406200  [C0231472, C0026845, C0277814, C1257890, C0224...\n",
       "4  26424709  [C0022558, C2939193, C0241311, C0018704, C0679..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = pd.read_csv('../data/concepts_per_document.csv')\\\n",
    "    .rename({'Concepts': 'true_CUIs'}, axis=1)\\\n",
    "    .drop('Unique_concepts', axis=1)\n",
    "gt['true_CUIs'] = gt['true_CUIs'].apply(eval).apply(set).apply(list).apply(lambda cuis: [cui[5:] for cui in cuis])\n",
    "gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c93546ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_emb = pd.concat([pd.read_csv(file) for file in glob.glob(emb_glob_regex)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0a11e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_to_cuis = concepts_emb.groupby('concept_name').apply(lambda x: list(x['CUI'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f445393",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_to_cuis = concepts_to_cuis.rename({0: 'CUIs'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e7fd839",
   "metadata": {},
   "outputs": [],
   "source": [
    "del concepts_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f70b6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_cuis(x): \n",
    "    result = {\n",
    "        'pred_cuis': sum(x['CUIs'], []),\n",
    "        'true_cuis': sum(x['true_CUIs'], [])\n",
    "    }\n",
    "    return pd.Series(result, index=['pred_cuis', 'true_cuis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "553b99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "UMLS_ST21pv_semantic_types_ids = {'T005', 'T007', 'T017', 'T022', 'T031', 'T033', 'T037', 'T038',\n",
    "'T058', 'T062', 'T074', 'T082', 'T091', 'T092', 'T097', 'T098', 'T103', 'T168', 'T170', 'T201', 'T204'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6444832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI</th>\n",
       "      <th>types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000722</td>\n",
       "      <td>[T170]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0000723</td>\n",
       "      <td>[T170]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0000731</td>\n",
       "      <td>[T033]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0000734</td>\n",
       "      <td>[T033]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0000742</td>\n",
       "      <td>[T005]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CUI   types\n",
       "0  C0000722  [T170]\n",
       "1  C0000723  [T170]\n",
       "2  C0000731  [T033]\n",
       "3  C0000734  [T033]\n",
       "4  C0000742  [T005]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_types = pd.read_csv('../data/MRSTY.RRF', sep='|', header=None, dtype=str)\n",
    "s_types = s_types[[0, 1]].rename({0: 'CUI', 1: 'type'}, axis=1)\n",
    "s_types = s_types.loc[s_types['type'].isin(UMLS_ST21pv_semantic_types_ids)]\n",
    "s_types = s_types.groupby('CUI').apply(lambda x: list(x['type'])).reset_index()\\\n",
    "    .rename({0: 'types'}, axis=1)\n",
    "s_types.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "676ba2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_types = dict(zip(s_types['CUI'], s_types['types']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a73d093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_cui_to_type(x):\n",
    "    result = {}\n",
    "    result['pred_type'] = [s_types[cui] for cui in set(x['pred_cuis']) if cui in s_types]\n",
    "    result['true_type'] = [s_types[cui] for cui in set(x['true_cuis']) if cui in s_types]\n",
    "    \n",
    "    result['pred_type'] = sum(result['pred_type'], [])\n",
    "    result['true_type'] = sum(result['true_type'], [])\n",
    "\n",
    "    return pd.Series(result, index=['pred_type', 'true_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a8e18283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_level</th>\n",
       "      <th>file</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.020486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_LDA_train_2022-12-07_15-04-23_em...</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.022509</td>\n",
       "      <td>0.017930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.012911</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>0.015413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.014166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...</td>\n",
       "      <td>0.478951</td>\n",
       "      <td>0.443718</td>\n",
       "      <td>0.460662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_LDA_train_2022-12-07_15-04-23_em...</td>\n",
       "      <td>0.423714</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.412677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.359718</td>\n",
       "      <td>0.390211</td>\n",
       "      <td>0.374344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.361691</td>\n",
       "      <td>0.377584</td>\n",
       "      <td>0.369467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  agg_level                                               file  precision  \\\n",
       "4       cui  tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...   0.016789   \n",
       "6       cui  tagged_1_word_LDA_train_2022-12-07_15-04-23_em...   0.014899   \n",
       "0       cui  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.012911   \n",
       "2       cui  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.011797   \n",
       "5      type  tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...   0.478951   \n",
       "7      type  tagged_1_word_LDA_train_2022-12-07_15-04-23_em...   0.423714   \n",
       "1      type  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.359718   \n",
       "3      type  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.361691   \n",
       "\n",
       "     recall        F1  \n",
       "4  0.026272  0.020486  \n",
       "6  0.022509  0.017930  \n",
       "0  0.019117  0.015413  \n",
       "2  0.017724  0.014166  \n",
       "5  0.443718  0.460662  \n",
       "7  0.402200  0.412677  \n",
       "1  0.390211  0.374344  \n",
       "3  0.377584  0.369467  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "stats = []\n",
    "for file in glob.glob(r'..\\results\\emb_tagger\\tagged_1*'):\n",
    "    tagged = explode_df(pd.read_csv(file))\n",
    "    tagged = tagged.merge(concepts_to_cuis, left_on='tag', right_on='concept_name', how='left')\\\n",
    "        .merge(gt, how='left')\n",
    "    \n",
    "    tagged = tagged.groupby('PMID').apply(concat_cuis).reset_index()\n",
    "    \n",
    "    tagged[['pred_type', 'true_type']] = tagged[['pred_cuis','true_cuis']].apply(change_cui_to_type, axis=1)\n",
    "    \n",
    "    TP_FN_FP_cuis = np.zeros((3,))\n",
    "    TP_FN_FP_types = np.zeros((3,))\n",
    "    for i, row in tagged.iterrows(): \n",
    "        TP_FN_FP_cuis += return_TP_FN_FP(row['pred_cuis'], row['true_cuis'])\n",
    "        TP_FN_FP_types += return_TP_FN_FP(row['pred_type'], row['true_type'])\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_cuis[0], TP_FN_FP_cuis[2])\n",
    "    recall_ = recall(TP_FN_FP_cuis[0], TP_FN_FP_cuis[1])\n",
    "    stats.append(('cui', os.path.basename(file), precision_, recall_, F1(precision_, recall_)))\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_types[0], TP_FN_FP_types[2])\n",
    "    recall_ = recall(TP_FN_FP_types[0], TP_FN_FP_types[1])\n",
    "    stats.append(('type', os.path.basename(file), precision_, recall_, F1(precision_, recall_)))\n",
    "\n",
    "pd.DataFrame(stats, columns=['agg_level', 'file', 'precision', 'recall', 'F1']).sort_values(['agg_level', 'file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7ac70d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"n = 300\\nrandom = pd.DataFrame()\\nrandom['true'] = [np.random.choice(21,size=(6,),replace=False) for _ in range(n)]\\nrandom['pred'] = [np.random.choice(21,size=(8,),replace=False) for _ in range(n)]\\nTP_FN_FP_random = np.zeros((3,))\\nfor i, row in random.iterrows(): \\n    TP_FN_FP_types += return_TP_FN_FP(row['true'], row['true'])\\n\\nprecision_ = precision(TP_FN_FP_types[0], TP_FN_FP_types[2])\\nrecall_ = recall(TP_FN_FP_types[0], TP_FN_FP_types[1])\\nprecision_, recall_, F1(precision_, recall_)\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"n = 300\n",
    "random = pd.DataFrame()\n",
    "random['true'] = [np.random.choice(21,size=(6,),replace=False) for _ in range(n)]\n",
    "random['pred'] = [np.random.choice(21,size=(8,),replace=False) for _ in range(n)]\n",
    "TP_FN_FP_random = np.zeros((3,))\n",
    "for i, row in random.iterrows(): \n",
    "    TP_FN_FP_types += return_TP_FN_FP(row['true'], row['true'])\n",
    "\n",
    "precision_ = precision(TP_FN_FP_types[0], TP_FN_FP_types[2])\n",
    "recall_ = recall(TP_FN_FP_types[0], TP_FN_FP_types[1])\n",
    "precision_, recall_, F1(precision_, recall_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "02b3592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_3552\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_level</th>\n",
       "      <th>file</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cui</td>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.029283</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cui</td>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.024451</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cui</td>\n",
       "      <td>ncbo_lda_test_21_results_2022-12-08.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cui</td>\n",
       "      <td>ncbo_lda_train_21_results_2022-12-08.csv</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.020486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_LDA_train_2022-12-07_15-04-23_em...</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.022509</td>\n",
       "      <td>0.017930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.012911</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>0.015413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.014166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>type</td>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.574675</td>\n",
       "      <td>0.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>type</td>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>0.009141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>type</td>\n",
       "      <td>ncbo_lda_test_21_results_2022-12-08.csv</td>\n",
       "      <td>0.024105</td>\n",
       "      <td>0.399209</td>\n",
       "      <td>0.045465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>type</td>\n",
       "      <td>ncbo_lda_train_21_results_2022-12-08.csv</td>\n",
       "      <td>0.031776</td>\n",
       "      <td>0.296527</td>\n",
       "      <td>0.057401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...</td>\n",
       "      <td>0.478951</td>\n",
       "      <td>0.443718</td>\n",
       "      <td>0.460662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_LDA_train_2022-12-07_15-04-23_em...</td>\n",
       "      <td>0.423714</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.412677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.359718</td>\n",
       "      <td>0.390211</td>\n",
       "      <td>0.374344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.361691</td>\n",
       "      <td>0.377584</td>\n",
       "      <td>0.369467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agg_level                                               file  precision  \\\n",
       "8        cui  bertopic_ncbo_fulldata_lemmatize_nostopwords_d...   0.000106   \n",
       "10       cui  bertopic_ncbo_fulldata_lemmatize_nostopwords_d...   0.000106   \n",
       "12       cui            ncbo_lda_test_21_results_2022-12-08.csv   0.000000   \n",
       "14       cui           ncbo_lda_train_21_results_2022-12-08.csv   0.000034   \n",
       "4        cui  tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...   0.016789   \n",
       "6        cui  tagged_1_word_LDA_train_2022-12-07_15-04-23_em...   0.014899   \n",
       "0        cui  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.012911   \n",
       "2        cui  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.011797   \n",
       "9       type  bertopic_ncbo_fulldata_lemmatize_nostopwords_d...   0.004637   \n",
       "11      type  bertopic_ncbo_fulldata_lemmatize_nostopwords_d...   0.004613   \n",
       "13      type            ncbo_lda_test_21_results_2022-12-08.csv   0.024105   \n",
       "15      type           ncbo_lda_train_21_results_2022-12-08.csv   0.031776   \n",
       "5       type  tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...   0.478951   \n",
       "7       type  tagged_1_word_LDA_train_2022-12-07_15-04-23_em...   0.423714   \n",
       "1       type  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.359718   \n",
       "3       type  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.361691   \n",
       "\n",
       "      recall        F1  \n",
       "8   0.029283  0.000212  \n",
       "10  0.024451  0.000211  \n",
       "12  0.000000  0.000000  \n",
       "14  0.000692  0.000064  \n",
       "4   0.026272  0.020486  \n",
       "6   0.022509  0.017930  \n",
       "0   0.019117  0.015413  \n",
       "2   0.017724  0.014166  \n",
       "9   0.574675  0.009200  \n",
       "11  0.497829  0.009141  \n",
       "13  0.399209  0.045465  \n",
       "15  0.296527  0.057401  \n",
       "5   0.443718  0.460662  \n",
       "7   0.402200  0.412677  \n",
       "1   0.390211  0.374344  \n",
       "3   0.377584  0.369467  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "for file in glob.glob('../results/bertopic_nbco/disambiguation/*disambiguation.csv') + glob.glob('../results/lda_ncbo/disambiguation/*'):\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[['PMID', 'disambiguation_fine_tuned_best_concept']]\n",
    "    df['disambiguation_fine_tuned_best_concept'] = df['disambiguation_fine_tuned_best_concept']\\\n",
    "        .apply(eval).apply(lambda x: list(x.values()))\n",
    "    df = df.explode('disambiguation_fine_tuned_best_concept')\n",
    "    df = df.merge(concepts_to_cuis, left_on='disambiguation_fine_tuned_best_concept', right_on='concept_name', how='left')\\\n",
    "        .drop('disambiguation_fine_tuned_best_concept', axis=1)\\\n",
    "        .merge(gt, how='left')\\\n",
    "        .rename({'CUIs': 'pred_cuis', 'true_CUIs': 'true_cuis'}, axis=1)\n",
    "    df['pred_cuis'] = df['pred_cuis'].apply(lambda x: [] if x != x else x)\n",
    "    df[['pred_type', 'true_type']] = df[['pred_cuis','true_cuis']].apply(change_cui_to_type, axis=1)\n",
    "    \n",
    "    TP_FN_FP_cuis = np.zeros((3,))\n",
    "    TP_FN_FP_types = np.zeros((3,))\n",
    "    for i, row in df.iterrows(): \n",
    "        TP_FN_FP_cuis += return_TP_FN_FP(row['pred_cuis'], row['true_cuis'])\n",
    "        TP_FN_FP_types += return_TP_FN_FP(row['pred_type'], row['true_type'])\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_cuis[0], TP_FN_FP_cuis[2])\n",
    "    recall_ = recall(TP_FN_FP_cuis[0], TP_FN_FP_cuis[1])\n",
    "    stats.append(('cui', os.path.basename(file), precision_, recall_, F1(precision_, recall_)))\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_types[0], TP_FN_FP_types[2])\n",
    "    recall_ = recall(TP_FN_FP_types[0], TP_FN_FP_types[1])\n",
    "    stats.append(('type', os.path.basename(file), precision_, recall_, F1(precision_, recall_)))\n",
    "stats = pd.DataFrame(stats, columns=['agg_level', 'file', 'precision', 'recall', 'F1'])\n",
    "stats.sort_values(['agg_level', 'file'])#.to_csv('../results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1f102472",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_names = {'../results/bertopic_nbco/disambiguation\\\\bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_test_disambiguation.csv': 'bertopic_ncbo_test',\n",
    " '../results/bertopic_nbco/disambiguation\\\\bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_train_disambiguation.csv': 'bertopic_ncbo_train',\n",
    " '../results/lda_ncbo/disambiguation\\\\ncbo_lda_test_21_results_2022-12-08.csv': 'lda_ncbo_test',\n",
    " '../results/lda_ncbo/disambiguation\\\\ncbo_lda_train_21_results_2022-12-08.csv': 'lda_ncbo_train',\n",
    " '..\\\\results\\\\emb_tagger\\\\tagged_1_word_bertopic_lemmatize_nostopwords_data_2022-11-28_19-41-48_test_emb_tagger_biobert.csv':'bertopic_emb_test',\n",
    " '..\\\\results\\\\emb_tagger\\\\tagged_1_word_bertopic_lemmatize_nostopwords_data_2022-11-28_19-41-48_train_emb_tagger_biobert.csv': 'bertopic_emb_train',\n",
    " '..\\\\results\\\\emb_tagger\\\\tagged_1_word_LDA_test_2022-12-07_15-04-23_emb_tagger_biobert.csv': 'lda_emb_test',\n",
    " '..\\\\results\\\\emb_tagger\\\\tagged_1_word_LDA_train_2022-12-07_15-04-23_emb_tagger_biobert.csv': 'lda_emb_train'}\n",
    "files_to_names = {os.path.basename(file): name for file, name in files_to_names.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "336bed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['file'] = stats['file'].map(files_to_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dcfb71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['precision','recall','F1']: \n",
    "    stats[col] = stats[col].apply(lambda x: round(100*x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "da5059f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.sort_values(['agg_level', 'file']).to_csv('../results/stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "51764603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_level</th>\n",
       "      <th>file</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cui</td>\n",
       "      <td>bertopic_emb_test</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cui</td>\n",
       "      <td>bertopic_emb_train</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cui</td>\n",
       "      <td>bertopic_ncbo_test</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cui</td>\n",
       "      <td>bertopic_ncbo_train</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cui</td>\n",
       "      <td>lda_emb_test</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cui</td>\n",
       "      <td>lda_emb_train</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cui</td>\n",
       "      <td>lda_ncbo_test</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cui</td>\n",
       "      <td>lda_ncbo_train</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type</td>\n",
       "      <td>bertopic_emb_test</td>\n",
       "      <td>35.97</td>\n",
       "      <td>39.02</td>\n",
       "      <td>37.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type</td>\n",
       "      <td>bertopic_emb_train</td>\n",
       "      <td>36.17</td>\n",
       "      <td>37.76</td>\n",
       "      <td>36.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>type</td>\n",
       "      <td>bertopic_ncbo_test</td>\n",
       "      <td>0.46</td>\n",
       "      <td>57.47</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>type</td>\n",
       "      <td>bertopic_ncbo_train</td>\n",
       "      <td>0.46</td>\n",
       "      <td>49.78</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>type</td>\n",
       "      <td>lda_emb_test</td>\n",
       "      <td>47.90</td>\n",
       "      <td>44.37</td>\n",
       "      <td>46.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>type</td>\n",
       "      <td>lda_emb_train</td>\n",
       "      <td>42.37</td>\n",
       "      <td>40.22</td>\n",
       "      <td>41.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>type</td>\n",
       "      <td>lda_ncbo_test</td>\n",
       "      <td>2.41</td>\n",
       "      <td>39.92</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>type</td>\n",
       "      <td>lda_ncbo_train</td>\n",
       "      <td>3.18</td>\n",
       "      <td>29.65</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agg_level                 file  precision  recall     F1\n",
       "0        cui    bertopic_emb_test       1.29    1.91   1.54\n",
       "2        cui   bertopic_emb_train       1.18    1.77   1.42\n",
       "8        cui   bertopic_ncbo_test       0.01    2.93   0.02\n",
       "10       cui  bertopic_ncbo_train       0.01    2.45   0.02\n",
       "4        cui         lda_emb_test       1.68    2.63   2.05\n",
       "6        cui        lda_emb_train       1.49    2.25   1.79\n",
       "12       cui        lda_ncbo_test       0.00    0.00   0.00\n",
       "14       cui       lda_ncbo_train       0.00    0.07   0.01\n",
       "1       type    bertopic_emb_test      35.97   39.02  37.43\n",
       "3       type   bertopic_emb_train      36.17   37.76  36.95\n",
       "9       type   bertopic_ncbo_test       0.46   57.47   0.92\n",
       "11      type  bertopic_ncbo_train       0.46   49.78   0.91\n",
       "5       type         lda_emb_test      47.90   44.37  46.07\n",
       "7       type        lda_emb_train      42.37   40.22  41.27\n",
       "13      type        lda_ncbo_test       2.41   39.92   4.55\n",
       "15      type       lda_ncbo_train       3.18   29.65   5.74"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.sort_values(['agg_level', 'file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b430ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
