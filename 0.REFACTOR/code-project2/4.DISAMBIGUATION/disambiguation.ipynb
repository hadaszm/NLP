{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import math\n",
    "import datetime\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeding(word,emb):\n",
    "    \"\"\"Get word embedding \"\"\"\n",
    "    return emb.loc[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tags_list_dict(row, with_sorting = False):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : list\n",
    "        list of lists keyword, concept\n",
    "    with_sorting : bool\n",
    "        should sorting be enables\n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    results : dict\n",
    "        initaly sorted (or random ordered) dictionary keyword : dict of concepts {concept : distance}\n",
    "    '''\n",
    "    result = {}\n",
    "    for tag in row:\n",
    "        key = tag[0].split(',')[0].upper()\n",
    "        value = tag[1].upper()\n",
    "        if key in result.keys():\n",
    "            if  value not in result[key]:\n",
    "                result[key][value]=1\n",
    "            else:\n",
    "                 result[key][value]+=1\n",
    "        else:\n",
    "            result[key]= {value:1}\n",
    "    if with_sorting:\n",
    "        for key in result.keys():\n",
    "            d = result[key]\n",
    "            d = {k:0 for k,v in dict(sorted(d.items(), key=lambda item: item[1], reverse = True)).items()}\n",
    "            result[key] = d\n",
    "    else:\n",
    "        for key in result.keys():\n",
    "            d = result[key]\n",
    "            d = {k:0 for k,v in d.items()}\n",
    "            result[key] = d\n",
    "        \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguation(current_selection,embedings, weigths, forced):\n",
    "    ''' \n",
    "    Parameters\n",
    "    ----------\n",
    "    current_selection : dict\n",
    "         dictionary keyword: list of all unique concepts\n",
    "    weigths: dict\n",
    "         the importance of given keyword\n",
    "    forced: bool\n",
    "        should the concept identical with keyword be the first\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    new_current_selction : dict\n",
    "        dictionary with new best selction of concepts\n",
    "    \n",
    "    '''\n",
    "    # we iterate over the current_selection MAX_ITER times\n",
    "    new_current_selction  = copy.deepcopy(current_selection)\n",
    "    should_stop = False\n",
    "    for i in range(7):\n",
    "\n",
    "        for keyword, concepts_list in new_current_selction.items():\n",
    "            distances = {} # for each possible concept calaculate the mean distance from other kewords (concepts of them)\n",
    "            if forced and  any([c== keyword for c in concepts_list.keys()]):\n",
    "                _ = [c != keyword for c in concepts_list.keys()]\n",
    "                distances = dict(zip(_,[1000]* len(_)))\n",
    "                distances[keyword] = 0\n",
    "            else:\n",
    "                for concept in concepts_list.keys():\n",
    "                    distances[concept] = []\n",
    "                    for k, current_best_tags in new_current_selction.items():\n",
    "                        # foreach keyword that is not a current one \n",
    "                        if k!=keyword:\n",
    "                            current_best_tag = list(current_best_tags.keys())[0] # the first out of list of concepts\n",
    "                            try:\n",
    "                                distances[concept].append(weigths[k]*math.dist(get_embeding(concept,embedings),get_embeding(current_best_tag,embedings))) # append distance from this concept\n",
    "                            except Exception as e:\n",
    "                                print(e)\n",
    "                    distances[concept] = np.mean(distances[concept]) # mean distance \n",
    "            new_current_selction[keyword] = dict(sorted(distances.items(), key=lambda item: item[1]))  # upadate the current selection of this keyword\n",
    "    return new_current_selction\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords_importance(grouped_data, tagger_data):\n",
    "    \"\"\"get keywords importance\"\"\"\n",
    "    return grouped_data.reset_index().merge(tagger_data[['PMID','topic_keywords']] ,on = 'PMID').set_index('text_to_annotate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_best_tags(data, n = 1):\n",
    "    \"\"\"how many best concepts to take\"\"\"\n",
    "    return [{k:sorted(v, key=v.get)[:n] for k,v in dd.items()} for dd in data['after_disambiguation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_disambiguation(data, tagger, embedings,column_name = 'ncbo_annotations_pairs' ,  weighting = False, sorting = False, forced = False, take_best = 1):\n",
    "    \"\"\"prepare data for disambiguation - read csv, eval, set index etc.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datas : DataFrames\n",
    "        DataFrame with keywords\n",
    "    tagger : DataFrames\n",
    "        DataFrame with keywords importance\n",
    "    embedings : DataFrames\n",
    "        DataFrame with keywords embedings\n",
    "    column_name : str\n",
    "        Name of the column with annotations\n",
    "    weigthing: bool\n",
    "        Should the weigthed voting be performed\n",
    "    sorting: bool\n",
    "        Should the initial sorting be performed\n",
    "    take_best : int\n",
    "        How many best concepts should be returned\n",
    "\n",
    "\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    data  : DataFrame\n",
    "    \"\"\"\n",
    "    grouped = data.groupby('text_to_annotate').nth(0)\n",
    "    # get importance for each keyword -> will be used if weighting True\n",
    "    grouped = keywords_importance(grouped, tagger )\n",
    "    grouped['possible_tags'] = grouped[column_name].apply(lambda r: create_tags_list_dict(r, sorting))\n",
    "\n",
    "    # disambiguation\n",
    "    res = []\n",
    "    for idx, row  in tqdm.tqdm(grouped.iterrows(), total = len(grouped)):\n",
    "        current_selection = row['possible_tags']\n",
    "        if not weighting:\n",
    "            weigths = dict(zip(list(row['topic_keywords'].keys()),[1] * len(row['topic_keywords'])))\n",
    "        else:\n",
    "            weigths = row['topic_keywords']\n",
    "        r = disambiguation(current_selection, embedings,weigths,forced)\n",
    "        res.append(r)\n",
    "    grouped['after_disambiguation'] = res\n",
    "    data = data.merge(grouped['after_disambiguation'].reset_index(), on = 'text_to_annotate' )\n",
    "    data['disambiguation_best_concept'] = get_n_best_tags(data, take_best)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_name, tagger_name, embedings_name):\n",
    "    \"\"\"prepare data for disambiguation - read csv, eval, set index etc.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_name : str\n",
    "        Path to get data\n",
    "    tagger_name : str\n",
    "        Path to save the results to (folder must exist).\n",
    "\n",
    "    embedings_name : str\n",
    "        Path to save the results to (folder must exist).\n",
    "\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    data, tagger, embedings : tuple (DataFrame, DataFrame, DataFrame) \n",
    "    \"\"\"\n",
    "\n",
    "    data = pd.read_csv(data_name)\n",
    "    data['ncbo_annotations_pairs'] = data['ncbo_annotations_pairs'].apply(eval)\n",
    "    data['ncbo_annotations_pairs']  = data['ncbo_annotations_pairs'].apply(lambda x : [[a[0].upper(),a[1]] for a in x])\n",
    "\n",
    "    tagger = pd.read_csv(tagger_name)\n",
    "    tagger['topic_keywords'] = tagger['topic_keywords'].apply(eval).apply(lambda x: {k.upper():v for k,v in dict(x).items()})\n",
    "\n",
    "\n",
    "    embedings = pd.read_csv(embedings_name)\n",
    "    embedings = embedings.set_index('words')\n",
    "    embedings.index = embedings.index.str.upper()\n",
    "    embedings = embedings[~embedings.index.duplicated(keep='first')]\n",
    "\n",
    "    return  data, tagger, embedings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_disambiguation(results_folder,data_path, tagger_path, embedings_path,timestamp,weigthing=False,sorting=False,forced = False):\n",
    "    \"\"\"Performs disambiguation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_folder : str\n",
    "        Path to save results\n",
    "    \n",
    "    data_path : str\n",
    "        Path to save the model to (folder must exist).\n",
    "\n",
    "    tagger_path : str\n",
    "        Path to save the results to (folder must exist).\n",
    "\n",
    "    embedings_path : str\n",
    "        Path to save the results to (folder must exist).\n",
    "\n",
    "    timestamp : str\n",
    "        Timestamp that will be added to filenames\n",
    "\n",
    "    weigthing: bool\n",
    "        Should the weigthed voting be performed\n",
    "\n",
    "    sorting: bool\n",
    "        Should the initial sorting be performed\n",
    "\n",
    "    forced: bool\n",
    "        If true: if the any concept is identical with keyword it is returned\n",
    "\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    result_path : str\n",
    "        Path to results\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    import pandas as pd\n",
    "    import os \n",
    "    import math\n",
    "    import numpy as np\n",
    "\n",
    "    data, tagger, embedings = prepare_data( data_path,tagger_path,embedings_path)\n",
    "    data = prepare_for_disambiguation(data,tagger,embedings,'ncbo_annotations_pairs',weigthing,sorting,forced)\n",
    "    data.to_csv(results_folder)\n",
    "\n",
    "    return results_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lda_results(data_path, num_topics = 10,num_keywords = 10):\n",
    "    from gensim import corpora, models\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    \"\"\"Performs lda keywords extraction for data after lemmatization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : str\n",
    "        Path to preprocessed dataset. Dataset must contain a column with name 'tokenized_words_lemmatize'.\n",
    "    timestamp : str\n",
    "        Timestamp of getting data\n",
    "    num_topic : int\n",
    "        Number of disired topics\n",
    "\n",
    "    num_keywords : int\n",
    "        Number of keywords per topic\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    result, topic_distribution,lda_model : (DataFrame,DataFrame,model)\n",
    "        DataFrame with reults, DataFrae with topic distribution and lda_model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def get_topic_distribution(lda_model, number_of_topics, number_of_keywords):\n",
    "        topics_distrib = {}\n",
    "        for t in lda_model.print_topics(number_of_topics,number_of_keywords):\n",
    "            topics_distrib[t[0]] =[(a.split('*')[1][1:-1],float(a.split(\"*\")[0])) for a in t[1].split(' + ')]\n",
    "        return topics_distrib\n",
    "\n",
    "\n",
    "    data = pd.read_csv(data_path)\n",
    "    columns = ['tokenized_sentences', 'tokenized_words_lemmatize']\n",
    "    for col in columns:\n",
    "        data[col] = data[col].apply(eval)\n",
    "\n",
    "    texts = data.groupby('PMID')['tokenized_words_lemmatize'].agg(lambda x: x.iloc[0]+x.iloc[1])\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    \n",
    "    lda_model = models.LdaMulticore(corpus=corpus,\n",
    "                                        id2word=dictionary,\n",
    "                                        num_topics=num_topics,\n",
    "                                        passes = 20)\n",
    "    doc_lda = lda_model[corpus]\n",
    "\n",
    "    topic_distribution = get_topic_distribution(lda_model,num_topics,num_keywords)\n",
    "    topics_results = pd.DataFrame.from_records([topic_distribution]).T.reset_index().rename(columns = {'index':'topic_number',0:'topic_keywords'})\n",
    "    topics_results['keywords'] = topics_results['topic_keywords'].apply(lambda x: [a[0] for a in x])\n",
    "\n",
    "    \n",
    "\n",
    "    docs= []\n",
    "    for doc in doc_lda:\n",
    "        docs.append({\n",
    "            'topic_number':doc[0][0],\n",
    "            'topic_probs': float(doc[0][1]),\n",
    "            'topic_keywords': topics_results.iloc[doc[0][0]]['topic_keywords'],\n",
    "            'keywords': topics_results.iloc[doc[0][0]]['keywords']\n",
    "\n",
    "        })\n",
    "\n",
    "    docs = pd.DataFrame.from_records(docs)\n",
    "\n",
    "    results = data[['PMID']].drop_duplicates().reset_index(drop=True).join(docs)\n",
    "    topics_results = pd.DataFrame.from_records([topic_distribution]).T.reset_index().rename(columns = {'index':'topic_number',0:'topic_keywords'})\n",
    "\n",
    "\n",
    "\n",
    "    return results,topics_results, lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_lda(data_path, models_path, results_path, timestamp, num_topics = 10,num_keywords = 10):\n",
    "    \"\"\"Performs lda keywords extraction for data after lemmatization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : str\n",
    "        Path to preprocessed dataset. Dataset must contain a column with name 'tokenized_words_lemmatize'.\n",
    "    \n",
    "    models_path : str\n",
    "        Path to save the model to (folder must exist).\n",
    "\n",
    "    results_path : str\n",
    "        Path to save the results to (folder must exist).\n",
    "\n",
    "    timestamp : str\n",
    "        Timestamp that will be added to filenames\n",
    "\n",
    "    num_topic : int\n",
    "        Number of disired topics\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    (result_path, model_save_name) : tuple\n",
    "        Frist element is the path to created file with extracted keywrods, second - path to created model.\n",
    "    \"\"\"\n",
    "\n",
    "    results,topics_results, lda_model =  get_lda_results(data_path, num_topics ,num_keywords)\n",
    "\n",
    "    results_path = os.path.join(os.path.join(results_path, f'lda_results_{timestamp}.csv'))\n",
    "    results.to_csv(results_path)\n",
    "\n",
    "    models_path = os.path.join(models_path,f\"lda_model_{timestamp}\")\n",
    "    lda_model.save(models_path)\n",
    "\n",
    "    return results_path,models_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITER = 7\n",
    "data_name = '../0.RESULTS/lda_ncbo/lda_ncbo_2023-01-17_23-48-04.csv'\n",
    "tagger_name = '../0.RESULTS/lda/lda_results_2023-01-17_22-31-53.csv'\n",
    "embeding_name = '../0.RESULTS/embeddings/ncbo_embeddings.csv'\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "weigthing = True\n",
    "sorting = True\n",
    "forced = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_extraction_method = 'lda'\n",
    "tagger = 'ncbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:06<00:00,  1.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../0.RESULTS/disambiguation/lda_ncbo_2023_01_18_22_54_12_no_sorting_no_weighting_no_forcing.csv'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_folder = f'../0.RESULTS/disambiguation/{keyword_extraction_method}_{tagger}_{timestamp}_no_sorting_no_weighting_no_forcing.csv'\n",
    "prepare_disambiguation(results_folder,data_name, tagger_name, embeding_name,timestamp,weigthing=False,sorting=False,forced = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:06<00:00,  1.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../0.RESULTS/disambiguation/lda_ncbo_2023_01_18_22_54_12_sorting_no_weighting_no_forcing.csv'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_folder = f'../0.RESULTS/disambiguation/{keyword_extraction_method}_{tagger}_{timestamp}_sorting_no_weighting_no_forcing.csv'\n",
    "prepare_disambiguation(results_folder,data_name, tagger_name, embeding_name,timestamp,weigthing=False,sorting=True,forced = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:06<00:00,  1.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../0.RESULTS/disambiguation/lda_ncbo_2023_01_18_22_54_12_sorting_weighting_no_forcing.csv'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_folder = f'../0.RESULTS/disambiguation/{keyword_extraction_method}_{tagger}_{timestamp}_sorting_weighting_no_forcing.csv'\n",
    "prepare_disambiguation(results_folder,data_name, tagger_name, embeding_name,timestamp,weigthing=False,sorting=True,forced = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:02<00:00,  3.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../0.RESULTS/disambiguation/lda_ncbo_2023_01_18_22_54_12_sorting_weighting_forcing.csv'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_folder = f'../0.RESULTS/disambiguation/{keyword_extraction_method}_{tagger}_{timestamp}_sorting_weighting_forcing.csv'\n",
    "prepare_disambiguation(results_folder,data_name, tagger_name, embeding_name,timestamp,weigthing=False,sorting=True,forced = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = '..//..//../CRAFT/results/bertopic_ncbo/bertopic_ncbo_data_2023-01-03_13-27-32.csv'\n",
    "tagger_name =  '..//..//..//CRAFT/results/bertopic/bertopic_lemmatize_nostopwords_data_2023-01-02_10-04-20.csv'\n",
    "embeding_name = '..//..//..//CRAFT/results/embedings/ncbo_embeddings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:07<00:00,  1.17it/s]\n",
      "100%|██████████| 9/9 [00:08<00:00,  1.10it/s]\n",
      "100%|██████████| 9/9 [00:09<00:00,  1.01s/it]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "data, tagger, embedings = prepare_data( data_name,tagger_name,embeding_name)\n",
    "data_no_no_no = prepare_for_disambiguation(data,tagger,embedings,'ncbo_annotations_pairs',False,False,False)\n",
    "data_s_no_no = prepare_for_disambiguation(data,tagger,embedings,'ncbo_annotations_pairs',False,True,False)\n",
    "data_s_w_no = prepare_for_disambiguation(data,tagger,embedings,'ncbo_annotations_pairs',True,True,False)\n",
    "data_s_w_f = prepare_for_disambiguation(data,tagger,embedings,'ncbo_annotations_pairs',True,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = data_no_no_no.drop_duplicates(subset = 'disambiguation_best_concept').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(data):\n",
    "    for q in data.items():\n",
    "        print(f\"{q[0]} : {q[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EAR': 0.08950458480353375,\n",
       " 'SENSORY': 0.08130253977745765,\n",
       " 'CELL': 0.06981591322762211,\n",
       " 'HAIR': 0.06967881078425237,\n",
       " 'TBX15': 0.05420145019839328,\n",
       " 'EXPRESSION': 0.051496847594213704,\n",
       " 'COCHLEA': 0.04863097864826702,\n",
       " 'DORSOVENTRAL': 0.04863097864826702,\n",
       " 'MUTANT': 0.04054045491499,\n",
       " 'PENDRIN': 0.03690696158244563}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger[tagger['PMID']==12585968].iloc[0]['topic_keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0--------------------------\n",
      "-----------SIMPLE DISAMBIGUATION-----------------\n",
      "QUININE : ['ORGANIC MOLECULAR ENTITY']\n",
      "TASTE : ['MULTICELLULAR ORGANISMAL PROCESS']\n",
      "DOPAMINE : ['ORGANIC MOLECULAR ENTITY']\n",
      "LEARNING : ['MULTICELLULAR ORGANISMAL PROCESS']\n",
      "MEMORY : ['MULTICELLULAR ORGANISMAL PROCESS']\n",
      "RECEPTOR : ['CHEMICAL VIEWED FUNCTIONALLY']\n",
      "\n",
      "------------INITIAL SORTING-----------------------\n",
      "QUININE : ['P-BLOCK MOLECULAR ENTITY']\n",
      "TASTE : ['BIOLOGICAL_PROCESS']\n",
      "DOPAMINE : ['P-BLOCK MOLECULAR ENTITY']\n",
      "LEARNING : ['BIOLOGICAL_PROCESS']\n",
      "MEMORY : ['BIOLOGICAL_PROCESS']\n",
      "RECEPTOR : ['CHEMICAL VIEWED FUNCTIONALLY']\n",
      "\n",
      "-----------INITIAL SORTING + WEIGHTING-------------\n",
      "QUININE : ['P-BLOCK MOLECULAR ENTITY']\n",
      "TASTE : ['BIOLOGICAL_PROCESS']\n",
      "DOPAMINE : ['P-BLOCK MOLECULAR ENTITY']\n",
      "LEARNING : ['BIOLOGICAL_PROCESS']\n",
      "MEMORY : ['BIOLOGICAL_PROCESS']\n",
      "RECEPTOR : ['CHEMICAL VIEWED FUNCTIONALLY']\n",
      "\n",
      "---------INITIAL SORTING + WEIGHTING + FORCING-----\n",
      "QUININE : ['QUININE']\n",
      "TASTE : ['OCCURRENT']\n",
      "DOPAMINE : ['DOPAMINE']\n",
      "LEARNING : ['LEARNING']\n",
      "MEMORY : ['MEMORY']\n",
      "RECEPTOR : ['RECEPTOR']\n",
      "\n",
      "---------------5--------------------------\n",
      "-----------SIMPLE DISAMBIGUATION-----------------\n",
      "GENETIC : ['DISEASE CHARACTERISTIC']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "MUSCLE : ['MATERIAL ENTITY']\n",
      "GENE : ['REGION']\n",
      "DISEASE : ['DISEASE OR DISORDER']\n",
      "\n",
      "------------INITIAL SORTING-----------------------\n",
      "GENETIC : ['DISEASE CHARACTERISTIC']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "MUSCLE : ['MATERIAL ENTITY']\n",
      "GENE : ['REGION']\n",
      "DISEASE : ['DISEASE OR DISORDER']\n",
      "\n",
      "-----------INITIAL SORTING + WEIGHTING-------------\n",
      "GENETIC : ['DISEASE CHARACTERISTIC']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "MUSCLE : ['MATERIAL ENTITY']\n",
      "GENE : ['REGION']\n",
      "DISEASE : ['DISEASE OR DISORDER']\n",
      "\n",
      "---------INITIAL SORTING + WEIGHTING + FORCING-----\n",
      "GENETIC : ['DISEASE CHARACTERISTIC']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "MUSCLE : ['MATERIAL ENTITY']\n",
      "GENE : ['GENE']\n",
      "DISEASE : ['DISEASE OR DISORDER']\n",
      "\n",
      "---------------24--------------------------\n",
      "-----------SIMPLE DISAMBIGUATION-----------------\n",
      "MOUSE : ['ENTITY']\n",
      "KIDNEY : ['ENTITY']\n",
      "SOX1 : ['MATERIAL ENTITY']\n",
      "CELL : ['ENTITY']\n",
      "FUNCTION : ['ENTITY']\n",
      "ROLE : ['ENTITY']\n",
      "DEVELOPMENT : ['ENTITY']\n",
      "GENE : ['BIOLOGICAL_REGION']\n",
      "SIGNALING : ['ENTITY']\n",
      "\n",
      "------------INITIAL SORTING-----------------------\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "KIDNEY : ['MATERIAL ENTITY']\n",
      "SOX1 : ['MATERIAL ENTITY']\n",
      "CELL : ['BIOLOGICAL ENTITY']\n",
      "FUNCTION : ['REALIZABLE ENTITY']\n",
      "ROLE : ['MATERIAL ENTITY']\n",
      "DEVELOPMENT : ['OCCURRENT']\n",
      "GENE : ['BIOLOGICAL_REGION']\n",
      "SIGNALING : ['OCCURRENT']\n",
      "\n",
      "-----------INITIAL SORTING + WEIGHTING-------------\n",
      "MOUSE : ['OBJECT']\n",
      "KIDNEY : ['ORGAN']\n",
      "SOX1 : ['OBJECT']\n",
      "CELL : ['CELL']\n",
      "FUNCTION : ['DISPOSITION']\n",
      "ROLE : ['ROLE']\n",
      "DEVELOPMENT : ['PROCESS']\n",
      "GENE : ['REGION']\n",
      "SIGNALING : ['PROCESS']\n",
      "\n",
      "---------INITIAL SORTING + WEIGHTING + FORCING-----\n",
      "MOUSE : ['OBJECT']\n",
      "KIDNEY : ['KIDNEY']\n",
      "SOX1 : ['OBJECT']\n",
      "CELL : ['CELL']\n",
      "FUNCTION : ['FUNCTION']\n",
      "ROLE : ['ROLE']\n",
      "DEVELOPMENT : ['OCCURRENT']\n",
      "GENE : ['GENE']\n",
      "SIGNALING : ['SIGNALING']\n",
      "\n",
      "---------------43--------------------------\n",
      "-----------SIMPLE DISAMBIGUATION-----------------\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "ITPR1 : ['MOLECULAR ENTITY']\n",
      "PROTEIN : ['MOLECULAR ENTITY']\n",
      "PAX6 : ['MOLECULAR ENTITY']\n",
      "MCOLN1 : ['MOLECULAR ENTITY']\n",
      "CELL : ['BIOLOGICAL ENTITY']\n",
      "FUNCTION : ['SPECIFICALLY DEPENDENT CONTINUANT']\n",
      "GENE : ['BIOLOGICAL_REGION']\n",
      "\n",
      "------------INITIAL SORTING-----------------------\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "ITPR1 : ['MATERIAL ENTITY']\n",
      "PROTEIN : ['MATERIAL ENTITY']\n",
      "PAX6 : ['MATERIAL ENTITY']\n",
      "MCOLN1 : ['MATERIAL ENTITY']\n",
      "CELL : ['BIOLOGICAL ENTITY']\n",
      "FUNCTION : ['REALIZABLE ENTITY']\n",
      "GENE : ['BIOLOGICAL_REGION']\n",
      "\n",
      "-----------INITIAL SORTING + WEIGHTING-------------\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "ITPR1 : ['MATERIAL ENTITY']\n",
      "PROTEIN : ['MATERIAL ENTITY']\n",
      "PAX6 : ['MATERIAL ENTITY']\n",
      "MCOLN1 : ['MATERIAL ENTITY']\n",
      "CELL : ['BIOLOGICAL ENTITY']\n",
      "FUNCTION : ['REALIZABLE ENTITY']\n",
      "GENE : ['BIOLOGICAL_REGION']\n",
      "\n",
      "---------INITIAL SORTING + WEIGHTING + FORCING-----\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "ITPR1 : ['MATERIAL ENTITY']\n",
      "PROTEIN : ['PROTEIN']\n",
      "PAX6 : ['MATERIAL ENTITY']\n",
      "MCOLN1 : ['MATERIAL ENTITY']\n",
      "CELL : ['CELL']\n",
      "FUNCTION : ['FUNCTION']\n",
      "GENE : ['GENE']\n",
      "\n",
      "---------------57--------------------------\n",
      "-----------SIMPLE DISAMBIGUATION-----------------\n",
      "CELL : ['BIOLOGICAL ENTITY']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "SEX : ['MATERIAL ENTITY']\n",
      "EMBRYO : ['MATERIAL ENTITY']\n",
      "EMBRYONIC : ['MATERIAL ENTITY']\n",
      "DEVELOPMENT : ['OCCURRENT']\n",
      "CHROMATIN : ['MATERIAL ENTITY']\n",
      "GENE : ['BIOLOGICAL_REGION']\n",
      "\n",
      "------------INITIAL SORTING-----------------------\n",
      "CELL : ['BIOLOGICAL ENTITY']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "SEX : ['MATERIAL ENTITY']\n",
      "EMBRYO : ['MATERIAL ENTITY']\n",
      "EMBRYONIC : ['MATERIAL ENTITY']\n",
      "DEVELOPMENT : ['OCCURRENT']\n",
      "CHROMATIN : ['MATERIAL ENTITY']\n",
      "GENE : ['BIOLOGICAL_REGION']\n",
      "\n",
      "-----------INITIAL SORTING + WEIGHTING-------------\n",
      "CELL : ['BIOLOGICAL ENTITY']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "SEX : ['MATERIAL ENTITY']\n",
      "EMBRYO : ['MATERIAL ENTITY']\n",
      "EMBRYONIC : ['MATERIAL ENTITY']\n",
      "DEVELOPMENT : ['OCCURRENT']\n",
      "CHROMATIN : ['MATERIAL ENTITY']\n",
      "GENE : ['BIOLOGICAL_REGION']\n",
      "\n",
      "---------INITIAL SORTING + WEIGHTING + FORCING-----\n",
      "CELL : ['CELL']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "SEX : ['MATERIAL ENTITY']\n",
      "EMBRYO : ['EMBRYO']\n",
      "EMBRYONIC : ['MATERIAL ENTITY']\n",
      "DEVELOPMENT : ['OCCURRENT']\n",
      "CHROMATIN : ['CHROMATIN']\n",
      "GENE : ['GENE']\n",
      "\n",
      "---------------75--------------------------\n",
      "-----------SIMPLE DISAMBIGUATION-----------------\n",
      "HAIR : ['MATERIAL ENTITY']\n",
      "CELL : ['BIOLOGICAL ENTITY']\n",
      "TBX15 : ['MATERIAL ENTITY']\n",
      "EAR : ['MATERIAL ENTITY']\n",
      "PENDRIN : ['MATERIAL ENTITY']\n",
      "COCHLEA : ['MATERIAL ENTITY']\n",
      "\n",
      "------------INITIAL SORTING-----------------------\n",
      "HAIR : ['MATERIAL ENTITY']\n",
      "CELL : ['BIOLOGICAL ENTITY']\n",
      "TBX15 : ['MATERIAL ENTITY']\n",
      "EAR : ['MATERIAL ENTITY']\n",
      "PENDRIN : ['MATERIAL ENTITY']\n",
      "COCHLEA : ['MATERIAL ENTITY']\n",
      "\n",
      "-----------INITIAL SORTING + WEIGHTING-------------\n",
      "HAIR : ['CONTINUANT']\n",
      "CELL : ['CONTINUANT']\n",
      "TBX15 : ['MATERIAL ENTITY']\n",
      "EAR : ['CONTINUANT']\n",
      "PENDRIN : ['MATERIAL ENTITY']\n",
      "COCHLEA : ['CONTINUANT']\n",
      "\n",
      "---------INITIAL SORTING + WEIGHTING + FORCING-----\n",
      "HAIR : ['MATERIAL ENTITY']\n",
      "CELL : ['CELL']\n",
      "TBX15 : ['MATERIAL ENTITY']\n",
      "EAR : ['EAR']\n",
      "PENDRIN : ['PENDRIN']\n",
      "COCHLEA : ['COCHLEA']\n",
      "\n",
      "---------------80--------------------------\n",
      "-----------SIMPLE DISAMBIGUATION-----------------\n",
      "MID1 : ['OBJECT']\n",
      "PROTEIN : ['OBJECT']\n",
      "RANBP2 : ['OBJECT']\n",
      "NUCLEUS : ['ORGANELLE']\n",
      "MICROTUBULE : ['ORGANELLE']\n",
      "ANNEXIN : ['OBJECT']\n",
      "CONSERVED : ['CONSERVED']\n",
      "\n",
      "------------INITIAL SORTING-----------------------\n",
      "MID1 : ['MATERIAL ENTITY']\n",
      "PROTEIN : ['MATERIAL ENTITY']\n",
      "RANBP2 : ['MATERIAL ENTITY']\n",
      "NUCLEUS : ['MATERIAL ENTITY']\n",
      "MICROTUBULE : ['MATERIAL ENTITY']\n",
      "ANNEXIN : ['MATERIAL ENTITY']\n",
      "CONSERVED : ['CONSERVED']\n",
      "\n",
      "-----------INITIAL SORTING + WEIGHTING-------------\n",
      "MID1 : ['OBJECT']\n",
      "PROTEIN : ['OBJECT']\n",
      "RANBP2 : ['OBJECT']\n",
      "NUCLEUS : ['MATERIAL ENTITY']\n",
      "MICROTUBULE : ['MATERIAL ENTITY']\n",
      "ANNEXIN : ['OBJECT']\n",
      "CONSERVED : ['CONSERVED']\n",
      "\n",
      "---------INITIAL SORTING + WEIGHTING + FORCING-----\n",
      "MID1 : ['MATERIAL ENTITY']\n",
      "PROTEIN : ['PROTEIN']\n",
      "RANBP2 : ['MATERIAL ENTITY']\n",
      "NUCLEUS : ['NUCLEUS']\n",
      "MICROTUBULE : ['MICROTUBULE']\n",
      "ANNEXIN : ['MATERIAL ENTITY']\n",
      "CONSERVED : ['CONSERVED']\n",
      "\n",
      "---------------88--------------------------\n",
      "-----------SIMPLE DISAMBIGUATION-----------------\n",
      "BAL : ['CHEMICAL ENTITY']\n",
      "DEVELOPMENT : ['DEVELOPMENTAL PROCESS']\n",
      "TRANSCRIPTION : ['CELLULAR PROCESS']\n",
      "LUNG : ['MATERIAL ENTITY']\n",
      "DNA : ['CHEMICAL ENTITY']\n",
      "GENE : ['BIOLOGICAL_REGION']\n",
      "ANTIOXIDANT : ['CHEMICAL ROLE']\n",
      "CONGENITAL : ['DISEASE CHARACTERISTIC']\n",
      "\n",
      "------------INITIAL SORTING-----------------------\n",
      "BAL : ['CHEMICAL ENTITY']\n",
      "DEVELOPMENT : ['DEVELOPMENTAL PROCESS']\n",
      "TRANSCRIPTION : ['CELLULAR PROCESS']\n",
      "LUNG : ['MATERIAL ENTITY']\n",
      "DNA : ['CHEMICAL ENTITY']\n",
      "GENE : ['BIOLOGICAL_REGION']\n",
      "ANTIOXIDANT : ['CHEMICAL ROLE']\n",
      "CONGENITAL : ['DISEASE CHARACTERISTIC']\n",
      "\n",
      "-----------INITIAL SORTING + WEIGHTING-------------\n",
      "BAL : ['MATERIAL ENTITY']\n",
      "DEVELOPMENT : ['OCCURRENT']\n",
      "TRANSCRIPTION : ['CELLULAR PROCESS']\n",
      "LUNG : ['MATERIAL ENTITY']\n",
      "DNA : ['MATERIAL ENTITY']\n",
      "GENE : ['REGION']\n",
      "ANTIOXIDANT : ['CHEMICAL ROLE']\n",
      "CONGENITAL : ['DISEASE CHARACTERISTIC']\n",
      "\n",
      "---------INITIAL SORTING + WEIGHTING + FORCING-----\n",
      "BAL : ['ACUTE DISEASE']\n",
      "DEVELOPMENT : ['DEVELOPMENTAL PROCESS']\n",
      "TRANSCRIPTION : ['CELLULAR PROCESS']\n",
      "LUNG : ['LUNG']\n",
      "DNA : ['DNA']\n",
      "GENE : ['GENE']\n",
      "ANTIOXIDANT : ['ANTIOXIDANT']\n",
      "CONGENITAL : ['CONGENITAL']\n",
      "\n",
      "---------------94--------------------------\n",
      "-----------SIMPLE DISAMBIGUATION-----------------\n",
      "RNA : ['ORGANIC AMINO COMPOUND']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "SAM68 : ['ORGANIC AMINO COMPOUND']\n",
      "BMP2 : ['ORGANIC AMINO COMPOUND']\n",
      "BMP4 : ['ORGANIC AMINO COMPOUND']\n",
      "GATA6 : ['ORGANIC AMINO COMPOUND']\n",
      "LIMB : ['ORGANIC AMINO COMPOUND']\n",
      "BONE : ['MATERIAL ENTITY']\n",
      "\n",
      "------------INITIAL SORTING-----------------------\n",
      "RNA : ['MATERIAL ENTITY']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "SAM68 : ['MATERIAL ENTITY']\n",
      "BMP2 : ['MATERIAL ENTITY']\n",
      "BMP4 : ['MATERIAL ENTITY']\n",
      "GATA6 : ['MATERIAL ENTITY']\n",
      "LIMB : ['MATERIAL ENTITY']\n",
      "BONE : ['MATERIAL ENTITY']\n",
      "\n",
      "-----------INITIAL SORTING + WEIGHTING-------------\n",
      "RNA : ['MATERIAL ENTITY']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "SAM68 : ['MATERIAL ENTITY']\n",
      "BMP2 : ['MATERIAL ENTITY']\n",
      "BMP4 : ['MATERIAL ENTITY']\n",
      "GATA6 : ['MATERIAL ENTITY']\n",
      "LIMB : ['MATERIAL ENTITY']\n",
      "BONE : ['MATERIAL ENTITY']\n",
      "\n",
      "---------INITIAL SORTING + WEIGHTING + FORCING-----\n",
      "RNA : ['RNA']\n",
      "MOUSE : ['MATERIAL ENTITY']\n",
      "SAM68 : ['MATERIAL ENTITY']\n",
      "BMP2 : ['MATERIAL ENTITY']\n",
      "BMP4 : ['MATERIAL ENTITY']\n",
      "GATA6 : ['MATERIAL ENTITY']\n",
      "LIMB : ['LIMB']\n",
      "BONE : ['MATERIAL ENTITY']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in idx:\n",
    "    print(f'---------------{i}--------------------------')\n",
    "    print(\"-----------SIMPLE DISAMBIGUATION-----------------\")\n",
    "    pretty_print(data_no_no_no['disambiguation_best_concept'].iloc[i])\n",
    "    print()\n",
    "    print(\"------------INITIAL SORTING-----------------------\")\n",
    "    pretty_print(data_s_no_no['disambiguation_best_concept'].iloc[i])\n",
    "    print()\n",
    "    print(\"-----------INITIAL SORTING + WEIGHTING-------------\")\n",
    "    pretty_print(data_s_w_no['disambiguation_best_concept'].iloc[i])\n",
    "    print()\n",
    "    print(\"---------INITIAL SORTING + WEIGHTING + FORCING-----\")\n",
    "    pretty_print(data_s_w_f['disambiguation_best_concept'].iloc[i])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
