{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6186f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3e95bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c8391290",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_glob_regex = '../results/embeddings/concepts_embeddings_*_biobert.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ec41667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(TP, FP): \n",
    "    return TP/(TP+FP)\n",
    "\n",
    "def recall(TP, FN): \n",
    "    return TP/(TP+FN)\n",
    "\n",
    "def F1(precision, recall):\n",
    "    return 2/(1/precision + 1/recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6a3c0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_TP_FN_FP(keywords, ground_truth):\n",
    "    keywords = set(keywords)\n",
    "    ground_truth = set(ground_truth)\n",
    "    TP = len(keywords.intersection(ground_truth) )\n",
    "    FN = len(keywords.difference(ground_truth))\n",
    "    FP = len(ground_truth.difference(keywords))\n",
    "    return np.array([TP, FN, FP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b3d33618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_list(pmid, pairs):\n",
    "    result = []\n",
    "    for pair in pairs:\n",
    "        result.append((pmid, pair[0], pair[1]))\n",
    "    return result\n",
    "\n",
    "def explode_df(df): \n",
    "    result = []\n",
    "    for i, row in df.iterrows(): \n",
    "        result += explode_list(row['PMID'], eval(row['ncbo_annotations_pairs']))\n",
    "    return pd.DataFrame(result, columns=['PMID', 'keyword', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e94ff6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_id(id_): \n",
    "    if ':' in id_:\n",
    "        id_ = id_.split(':')\n",
    "    else: \n",
    "        id_ = id_.split('_')\n",
    "    try:\n",
    "        id_[1] = int(id_[1])\n",
    "    except (ValueError, IndexError) as e: \n",
    "        pass\n",
    "    return tuple(id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "62a6a8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MentionTextSegment</th>\n",
       "      <th>id</th>\n",
       "      <th>PMID</th>\n",
       "      <th>ontology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biological pigment</td>\n",
       "      <td>(chebi, 26130)</td>\n",
       "      <td>11532192</td>\n",
       "      <td>chebi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cation</td>\n",
       "      <td>(chebi, 36916)</td>\n",
       "      <td>11897010</td>\n",
       "      <td>chebi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ion</td>\n",
       "      <td>(chebi, 24870)</td>\n",
       "      <td>11897010</td>\n",
       "      <td>chebi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chromogenic compound</td>\n",
       "      <td>(chebi, 75050)</td>\n",
       "      <td>12079497</td>\n",
       "      <td>chebi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electron</td>\n",
       "      <td>(chebi, 10545)</td>\n",
       "      <td>12546709</td>\n",
       "      <td>chebi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MentionTextSegment              id      PMID ontology\n",
       "0    biological pigment  (chebi, 26130)  11532192    chebi\n",
       "1                cation  (chebi, 36916)  11897010    chebi\n",
       "2                   ion  (chebi, 24870)  11897010    chebi\n",
       "3  chromogenic compound  (chebi, 75050)  12079497    chebi\n",
       "4              electron  (chebi, 10545)  12546709    chebi"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = []\n",
    "for file in glob.glob('../CRAFT/data/*/annotations.csv'): \n",
    "    onto = os.path.basename(os.path.dirname(file))\n",
    "    if 'GO_' in onto:\n",
    "        onto = 'GO'\n",
    "    tmp = pd.read_csv(file)\n",
    "    tmp['ontology'] = onto.lower()\n",
    "    annotations.append(tmp)\n",
    "annotations = pd.concat(annotations).drop(['Unnamed: 0','StartIndex','EndIndex'],axis=1)\\\n",
    "    .rename({'EntityID': 'id'}, axis=1)\n",
    "annotations['id'] = annotations['id'].apply(lambda x: x.lower()).apply(process_id)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "87c70c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chebi', 'cl', 'go', 'mop', 'ncbitaxon', 'pr', 'so', 'uberon'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(annotations['id'].apply(lambda x: x[0]).drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "05e3d13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>keyword</th>\n",
       "      <th>concept</th>\n",
       "      <th>id</th>\n",
       "      <th>ontology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PMID, keyword, concept, id, ontology]\n",
       "Index: []"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tags = pd.concat([pd.read_csv(file) for file in glob.glob('../CRAFT/results/emb_tagger/*')])\n",
    "all_tags[all_tags['id'].isin([\n",
    "'1058',\n",
    "'8620',\n",
    "'BFO_0000023',\n",
    "'BFO_0000034',\n",
    "'CARO_0000013',\n",
    "'ENVO_01000739',\n",
    "'FOODON_00003004',\n",
    "'MGI:1890498',\n",
    "'MONDO_0021140',\n",
    "'MONDO_0021152',\n",
    "'NCBITaxon_family', \n",
    "'UPHENO_0001001',\n",
    "'WBGene00003937',\n",
    "'WBGene00004950',\n",
    "'WBGene00006560',\n",
    "'WBGene00011828',\n",
    "'main.html?id=1591873',\n",
    "'main.html?id=2666',\n",
    "'main.html?id=620991'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d416bd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chebi_134360',\n",
       " 'chebi_15854',\n",
       " 'chebi_18243',\n",
       " 'chebi_190453',\n",
       " 'chebi_190456',\n",
       " 'chebi_194078',\n",
       " 'chebi_22586',\n",
       " 'chebi_23888',\n",
       " 'chebi_24621',\n",
       " 'chebi_36080',\n",
       " 'chebi_48706',\n",
       " 'chebi_50906',\n",
       " 'chebi_52217',\n",
       " 'chebi_5391',\n",
       " 'chebi_60004',\n",
       " 'chebi_75710',\n",
       " 'chebi_86222',\n",
       " 'cl_0',\n",
       " 'cl_210',\n",
       " 'go_120302',\n",
       " 'go_23052',\n",
       " 'go_30496',\n",
       " 'go_31099',\n",
       " 'go_36166',\n",
       " 'go_40007',\n",
       " 'go_46903',\n",
       " 'go_5634',\n",
       " 'go_5874',\n",
       " 'go_725',\n",
       " 'go_7612',\n",
       " 'go_7613',\n",
       " 'go_785',\n",
       " 'ncbitaxon_1088410',\n",
       " 'ncbitaxon_114188',\n",
       " 'ncbitaxon_1265449',\n",
       " 'ncbitaxon_1430977',\n",
       " 'ncbitaxon_155026',\n",
       " 'ncbitaxon_1655545',\n",
       " 'ncbitaxon_1732204',\n",
       " 'ncbitaxon_1768868',\n",
       " 'ncbitaxon_1869227',\n",
       " 'ncbitaxon_274080',\n",
       " 'ncbitaxon_32644',\n",
       " 'ncbitaxon_336906',\n",
       " 'ncbitaxon_364787',\n",
       " 'ncbitaxon_448188',\n",
       " 'ncbitaxon_family',\n",
       " 'pr_1',\n",
       " 'pr_13716',\n",
       " 'pr_15039',\n",
       " 'pr_44676',\n",
       " 'pr_50012',\n",
       " 'pr_60049',\n",
       " 'pr_q8vi36',\n",
       " 'so_1023',\n",
       " 'so_167',\n",
       " 'so_2033',\n",
       " 'so_352',\n",
       " 'so_667',\n",
       " 'so_704',\n",
       " 'so_783',\n",
       " 'so_856',\n",
       " 'so_900',\n",
       " 'so_984',\n",
       " 'uberon_1021',\n",
       " 'uberon_12101',\n",
       " 'uberon_1443',\n",
       " 'uberon_1690',\n",
       " 'uberon_1844',\n",
       " 'uberon_2007001',\n",
       " 'uberon_2048',\n",
       " 'uberon_2101',\n",
       " 'uberon_2113',\n",
       " 'uberon_2371',\n",
       " 'uberon_3129',\n",
       " 'uberon_341',\n",
       " 'uberon_5295',\n",
       " 'uberon_5870',\n",
       " 'uberon_8816',\n",
       " 'uberon_922',\n",
       " 'uberon_955'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pd.concat([pd.read_csv(file) for file in glob.glob('../CRAFT/results/emb_tagger/*')])['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "875d5549",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_groupped = annotations.groupby('PMID').apply(lambda x: \n",
    "                                 pd.Series({'true_ids': set(x['id'])}, index=['true_ids'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "648fd034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bertopic_tagged.csv</td>\n",
       "      <td>5.711264</td>\n",
       "      <td>11.933702</td>\n",
       "      <td>7.725322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lda_tagged.csv</td>\n",
       "      <td>4.019038</td>\n",
       "      <td>8.315098</td>\n",
       "      <td>5.418895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file  precision     recall        F1\n",
       "0  bertopic_tagged.csv   5.711264  11.933702  7.725322\n",
       "1       lda_tagged.csv   4.019038   8.315098  5.418895"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = []\n",
    "for file in glob.glob('../CRAFT/results/emb_tagger/*'):\n",
    "    tagged = pd.read_csv(file)\n",
    "    tagged['id'] = tagged['id'].apply(lambda x: x.lower()).apply(process_id)\n",
    "    tagged_groupped = tagged.groupby('PMID').apply(lambda x: \n",
    "                                 pd.Series({'pred_ids': set(x['id'])}, index=['pred_ids'])).reset_index()\n",
    "    merged = tagged_groupped.merge(annotations_groupped,how='outer')\n",
    "    \n",
    "    \n",
    "    TP_FN_FP_ids = np.zeros((3,))\n",
    "    for i, row in merged.iterrows(): \n",
    "        TP_FN_FP_ids += return_TP_FN_FP(row['pred_ids'], row['true_ids'])\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_ids[0],TP_FN_FP_ids[2])\n",
    "    recall_ = recall(TP_FN_FP_ids[0], TP_FN_FP_ids[1])\n",
    "    stats.append((os.path.basename(file), precision_*100, recall_*100, 100*F1(precision_, recall_)))\n",
    "pd.DataFrame(stats, columns=['file', 'precision', 'recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86aac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontologies_mappings = pd.concat([pd.read_csv(file) for file in glob.glob('../CRAFT/data/ontologies_mappings/*')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b5670f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ncbo_concepts_used = pd.concat([pd.read_csv(file) for file in glob.glob('../CRAFT/results/disambiguation/*')])\n",
    "text_to_id = dict()\n",
    "for elem in sum(all_ncbo_concepts_used['ncbo_annotations'].apply(eval), []):\n",
    "    id_ = elem['annotatedClass']['@id'].split('/')[-1]\n",
    "    for annotation in elem['annotations']:\n",
    "        text_to_id[annotation['text'].lower()] = id_\n",
    "all_ncbo_concepts_used = {elem['annotatedClass']['@id'].split('/')[-1] for elem in sum(all_ncbo_concepts_used['ncbo_annotations'].apply(eval), [])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e999dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_concepts = ontologies_mappings[ontologies_mappings['id'].isin(all_ncbo_concepts_used)].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1704ded8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T016', 'T025', 'T192'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ncbo_concepts_used.difference(filtered_concepts['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a2e5d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontologies_mappings['label'] = ontologies_mappings['label'].apply(lambda x: x.lower())\n",
    "label_to_ids = ontologies_mappings.groupby('label').apply(lambda x: list(set(x['id']))).reset_index().rename({0: 'ids'}, axis=1)\n",
    "label_to_ids = dict(zip(label_to_ids['label'], label_to_ids['ids']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b2fb9756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_id(id_): \n",
    "    if ':' in id_:\n",
    "        id_ = id_.split(':')\n",
    "    else: \n",
    "        id_ = id_.split('_')\n",
    "    try:\n",
    "        id_[1] = int(id_[1])\n",
    "    except (ValueError, IndexError) as e: \n",
    "        pass\n",
    "    return tuple(id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "53599fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CELL': ['BIOLOGICAL ENTITY'],\n",
       " 'MOUSE': ['MATERIAL ENTITY'],\n",
       " 'EMBRYO': ['MATERIAL ENTITY'],\n",
       " 'EMBRYONIC': ['MATERIAL ENTITY'],\n",
       " 'DNA': ['MATERIAL ENTITY'],\n",
       " 'GENE': ['BIOLOGICAL_REGION']}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(file)['disambiguation_best_concept'].apply(eval).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "972d0adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     710\n",
      "label    710\n",
      "id       705\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_8564\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     710\n",
      "label    710\n",
      "id       705\n",
      "dtype: int64\n",
      "PMID     710\n",
      "label    710\n",
      "id       705\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_8564\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     710\n",
      "label    710\n",
      "id       705\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_8564\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     710\n",
      "label    710\n",
      "id       705\n",
      "dtype: int64\n",
      "PMID     589\n",
      "label    589\n",
      "id       559\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_8564\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     589\n",
      "label    589\n",
      "id       559\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_8564\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     589\n",
      "label    589\n",
      "id       559\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_8564\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_03_18_02_32_train_sorted.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_03_18_02_32_weigthed_and_sorted.csv</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.001689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_no_sorted_no_weighted.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_sorted_no_weighted.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_weighted_and_sorted.csv</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.001689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_no_sorted_no_weighted.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_sorted_no_weighted.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_weighted_and_sorted.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              file  \\\n",
       "0           bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_03_18_02_32_train_sorted.csv   \n",
       "1    bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_03_18_02_32_weigthed_and_sorted.csv   \n",
       "2  bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_no_sorted_no_weighted.csv   \n",
       "3     bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_sorted_no_weighted.csv   \n",
       "4    bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_weighted_and_sorted.csv   \n",
       "5       lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_no_sorted_no_weighted.csv   \n",
       "6          lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_sorted_no_weighted.csv   \n",
       "7         lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_weighted_and_sorted.csv   \n",
       "\n",
       "   precision    recall        F1  \n",
       "0   0.000000  0.000000  0.000000  \n",
       "1   0.001058  0.004193  0.001689  \n",
       "2   0.000000  0.000000  0.000000  \n",
       "3   0.000000  0.000000  0.000000  \n",
       "4   0.001058  0.004193  0.001689  \n",
       "5   0.000000  0.000000  0.000000  \n",
       "6   0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = []\n",
    "for file in glob.glob('../CRAFT/results/disambiguation/*'):\n",
    "    dis = pd.read_csv(file) \n",
    "    dis['disambiguation_best_concept'] = dis['disambiguation_best_concept'].apply(eval).apply(lambda x: [v[0].lower() for v in x.values()])\n",
    "    dis = dis[['PMID', 'disambiguation_best_concept']].explode('disambiguation_best_concept')\\\n",
    "        .rename({'disambiguation_best_concept': 'label'}, axis=1)\n",
    "    \n",
    "    dis['id'] = dis['label'].map(label_to_ids)\n",
    "    print(dis.count())\n",
    "    dis['id'] = dis['id'].apply(lambda x: x if x == x else [])\n",
    "\n",
    "    dis['id'] = dis['id'].apply(lambda x: [process_id(elem.lower()) for elem in x])\n",
    "    dis = dis.groupby('PMID').apply(lambda x: \n",
    "                     pd.Series({'pred_ids': set(sum(x['id'], []))}, index=['pred_ids'])).reset_index()\n",
    "    merged = dis.merge(annotations_groupped,on=['PMID'], how='outer')\n",
    "    \n",
    "    TP_FN_FP_ids = np.zeros((3,))\n",
    "    for i, row in merged.iterrows(): \n",
    "        TP_FN_FP_ids += return_TP_FN_FP(row['pred_ids'], row['true_ids'])\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_ids[0],TP_FN_FP_ids[2])\n",
    "    recall_ = recall(TP_FN_FP_ids[0], TP_FN_FP_ids[1])\n",
    "    stats.append((os.path.basename(file), precision_, recall_, F1(precision_, recall_)))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(stats, columns=['file', 'precision', 'recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437eb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e1fc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45157ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c057315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c69df14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_03_18_02_32_train_sorted.csv</td>\n",
       "      <td>0.052882</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.076894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_03_18_02_32_weigthed_and_sorted.csv</td>\n",
       "      <td>0.052882</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.076894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_no_sorted_no_weighted.csv</td>\n",
       "      <td>0.052882</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.076894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_sorted_no_weighted.csv</td>\n",
       "      <td>0.052882</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.076894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_weighted_and_sorted.csv</td>\n",
       "      <td>0.052882</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.076894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_no_sorted_no_weighted.csv</td>\n",
       "      <td>0.042834</td>\n",
       "      <td>0.137521</td>\n",
       "      <td>0.065323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_sorted_no_weighted.csv</td>\n",
       "      <td>0.042834</td>\n",
       "      <td>0.137521</td>\n",
       "      <td>0.065323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_weighted_and_sorted.csv</td>\n",
       "      <td>0.042834</td>\n",
       "      <td>0.137521</td>\n",
       "      <td>0.065323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              file  \\\n",
       "0           bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_03_18_02_32_train_sorted.csv   \n",
       "1    bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_03_18_02_32_weigthed_and_sorted.csv   \n",
       "2  bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_no_sorted_no_weighted.csv   \n",
       "3     bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_sorted_no_weighted.csv   \n",
       "4    bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_51_30_weighted_and_sorted.csv   \n",
       "5       lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_no_sorted_no_weighted.csv   \n",
       "6          lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_sorted_no_weighted.csv   \n",
       "7         lda_ncbo_fulldata_lemmatize_nostopwords_data_2023_01_04_17_37_13_weighted_and_sorted.csv   \n",
       "\n",
       "   precision    recall        F1  \n",
       "0   0.052882  0.140845  0.076894  \n",
       "1   0.052882  0.140845  0.076894  \n",
       "2   0.052882  0.140845  0.076894  \n",
       "3   0.052882  0.140845  0.076894  \n",
       "4   0.052882  0.140845  0.076894  \n",
       "5   0.042834  0.137521  0.065323  \n",
       "6   0.042834  0.137521  0.065323  \n",
       "7   0.042834  0.137521  0.065323  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = []\n",
    "for file in glob.glob('../CRAFT/results/disambiguation/*'):\n",
    "    dis = pd.read_csv(file) \n",
    "    dis['disambiguation_best_concept'] = dis['disambiguation_best_concept'].apply(eval).apply(lambda x: [k.lower() for k in x.keys()])\n",
    "    dis = dis[['PMID', 'disambiguation_best_concept']].explode('disambiguation_best_concept')\\\n",
    "        .rename({'disambiguation_best_concept': 'label'}, axis=1)\n",
    "    dis['id'] = dis['label'].map(text_to_id).apply(lambda x: process_id(x.lower()))\n",
    "    dis = dis.groupby('PMID').apply(lambda x: \n",
    "                     pd.Series({'pred_ids': set(x['id'])}, index=['pred_ids'])).reset_index()\n",
    "    merged = dis.merge(annotations_groupped,on=['PMID'], how='outer')\n",
    "    \n",
    "    TP_FN_FP_ids = np.zeros((3,))\n",
    "    for i, row in merged.iterrows(): \n",
    "        TP_FN_FP_ids += return_TP_FN_FP(row['pred_ids'], row['true_ids'])\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_ids[0],TP_FN_FP_ids[2])\n",
    "    recall_ = recall(TP_FN_FP_ids[0], TP_FN_FP_ids[1])\n",
    "    stats.append((os.path.basename(file), precision_, recall_, F1(precision_, recall_)))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(stats, columns=['file', 'precision', 'recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3ee7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8e56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d6fc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ce400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d5b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e66a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>true_CUIs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25763772</td>\n",
       "      <td>[C0035204, C0033809, C0444245, C0010674, C0032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25847295</td>\n",
       "      <td>[C0010749, C0007620, C0376669, C0219474, C0678...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26316050</td>\n",
       "      <td>[C1257792, C1849265, C2603343, C0442069, C1708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26406200</td>\n",
       "      <td>[C0205143, C0037949, C0277814, C0679646, C0231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26424709</td>\n",
       "      <td>[C0008819, C0018704, C0237096, C0679646, C0241...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                          true_CUIs\n",
       "0  25763772  [C0035204, C0033809, C0444245, C0010674, C0032...\n",
       "1  25847295  [C0010749, C0007620, C0376669, C0219474, C0678...\n",
       "2  26316050  [C1257792, C1849265, C2603343, C0442069, C1708...\n",
       "3  26406200  [C0205143, C0037949, C0277814, C0679646, C0231...\n",
       "4  26424709  [C0008819, C0018704, C0237096, C0679646, C0241..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = pd.read_csv('../data/concepts_per_document.csv')\\\n",
    "    .rename({'Concepts': 'true_CUIs'}, axis=1)\\\n",
    "    .drop('Unique_concepts', axis=1)\n",
    "gt['true_CUIs'] = gt['true_CUIs'].apply(eval).apply(set).apply(list).apply(lambda cuis: [cui[5:] for cui in cuis])\n",
    "gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c93546ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_emb = pd.concat([pd.read_csv(file) for file in glob.glob(emb_glob_regex)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a11e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_to_cuis = concepts_emb.groupby('concept_name').apply(lambda x: list(x['CUI'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f445393",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_to_cuis = concepts_to_cuis.rename({0: 'CUIs'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e7fd839",
   "metadata": {},
   "outputs": [],
   "source": [
    "del concepts_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f70b6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_cuis(x): \n",
    "    result = {\n",
    "        'pred_cuis': sum(x['CUIs'], []),\n",
    "        'true_cuis': sum(x['true_CUIs'], [])\n",
    "    }\n",
    "    return pd.Series(result, index=['pred_cuis', 'true_cuis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "553b99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "UMLS_ST21pv_semantic_types_ids = {'T005', 'T007', 'T017', 'T022', 'T031', 'T033', 'T037', 'T038',\n",
    "'T058', 'T062', 'T074', 'T082', 'T091', 'T092', 'T097', 'T098', 'T103', 'T168', 'T170', 'T201', 'T204'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6444832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI</th>\n",
       "      <th>types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000722</td>\n",
       "      <td>[T170]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0000723</td>\n",
       "      <td>[T170]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0000731</td>\n",
       "      <td>[T033]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0000734</td>\n",
       "      <td>[T033]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0000742</td>\n",
       "      <td>[T005]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CUI   types\n",
       "0  C0000722  [T170]\n",
       "1  C0000723  [T170]\n",
       "2  C0000731  [T033]\n",
       "3  C0000734  [T033]\n",
       "4  C0000742  [T005]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_types = pd.read_csv('../data/MRSTY.RRF', sep='|', header=None, dtype=str)\n",
    "s_types = s_types[[0, 1]].rename({0: 'CUI', 1: 'type'}, axis=1)\n",
    "s_types = s_types.loc[s_types['type'].isin(UMLS_ST21pv_semantic_types_ids)]\n",
    "s_types = s_types.groupby('CUI').apply(lambda x: list(x['type'])).reset_index()\\\n",
    "    .rename({0: 'types'}, axis=1)\n",
    "s_types.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "676ba2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_types = dict(zip(s_types['CUI'], s_types['types']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a73d093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_cui_to_type(x):\n",
    "    result = {}\n",
    "    result['pred_type'] = [s_types[cui] for cui in set(x['pred_cuis']) if cui in s_types]\n",
    "    result['true_type'] = [s_types[cui] for cui in set(x['true_cuis']) if cui in s_types]\n",
    "    \n",
    "    result['pred_type'] = sum(result['pred_type'], [])\n",
    "    result['true_type'] = sum(result['true_type'], [])\n",
    "\n",
    "    return pd.Series(result, index=['pred_type', 'true_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8e18283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_level</th>\n",
       "      <th>file</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.020486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_LDA_train_2022-12-07_15-04-23_em...</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.022509</td>\n",
       "      <td>0.017930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.012911</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>0.015413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.014166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...</td>\n",
       "      <td>0.478951</td>\n",
       "      <td>0.443718</td>\n",
       "      <td>0.460662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_LDA_train_2022-12-07_15-04-23_em...</td>\n",
       "      <td>0.423714</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.412677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.359718</td>\n",
       "      <td>0.390211</td>\n",
       "      <td>0.374344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.361691</td>\n",
       "      <td>0.377584</td>\n",
       "      <td>0.369467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  agg_level                                               file  precision  \\\n",
       "4       cui  tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...   0.016789   \n",
       "6       cui  tagged_1_word_LDA_train_2022-12-07_15-04-23_em...   0.014899   \n",
       "0       cui  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.012911   \n",
       "2       cui  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.011797   \n",
       "5      type  tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...   0.478951   \n",
       "7      type  tagged_1_word_LDA_train_2022-12-07_15-04-23_em...   0.423714   \n",
       "1      type  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.359718   \n",
       "3      type  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.361691   \n",
       "\n",
       "     recall        F1  \n",
       "4  0.026272  0.020486  \n",
       "6  0.022509  0.017930  \n",
       "0  0.019117  0.015413  \n",
       "2  0.017724  0.014166  \n",
       "5  0.443718  0.460662  \n",
       "7  0.402200  0.412677  \n",
       "1  0.390211  0.374344  \n",
       "3  0.377584  0.369467  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "stats = []\n",
    "for file in glob.glob(r'..\\results\\emb_tagger\\tagged_1*'):\n",
    "    tagged = explode_df(pd.read_csv(file))\n",
    "    tagged = tagged.merge(concepts_to_cuis, left_on='tag', right_on='concept_name', how='left')\\\n",
    "        .merge(gt, how='left')\n",
    "    \n",
    "    tagged = tagged.groupby('PMID').apply(concat_cuis).reset_index()\n",
    "    \n",
    "    tagged[['pred_type', 'true_type']] = tagged[['pred_cuis','true_cuis']].apply(change_cui_to_type, axis=1)\n",
    "    \n",
    "    TP_FN_FP_cuis = np.zeros((3,))\n",
    "    TP_FN_FP_types = np.zeros((3,))\n",
    "    for i, row in tagged.iterrows(): \n",
    "        TP_FN_FP_cuis += return_TP_FN_FP(row['pred_cuis'], row['true_cuis'])\n",
    "        TP_FN_FP_types += return_TP_FN_FP(row['pred_type'], row['true_type'])\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_cuis[0], TP_FN_FP_cuis[2])\n",
    "    recall_ = recall(TP_FN_FP_cuis[0], TP_FN_FP_cuis[1])\n",
    "    stats.append(('cui', os.path.basename(file), precision_, recall_, F1(precision_, recall_)))\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_types[0], TP_FN_FP_types[2])\n",
    "    recall_ = recall(TP_FN_FP_types[0], TP_FN_FP_types[1])\n",
    "    stats.append(('type', os.path.basename(file), precision_, recall_, F1(precision_, recall_)))\n",
    "\n",
    "pd.DataFrame(stats, columns=['agg_level', 'file', 'precision', 'recall', 'F1']).sort_values(['agg_level', 'file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02b3592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_23616\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_level</th>\n",
       "      <th>file</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cui</td>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.029283</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cui</td>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.024451</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cui</td>\n",
       "      <td>ncbo_lda_test_21_results_2022-12-08.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cui</td>\n",
       "      <td>ncbo_lda_train_21_results_2022-12-08.csv</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.020486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_LDA_train_2022-12-07_15-04-23_em...</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.022509</td>\n",
       "      <td>0.017930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.012911</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>0.015413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cui</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.014166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>type</td>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.574675</td>\n",
       "      <td>0.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>type</td>\n",
       "      <td>bertopic_ncbo_fulldata_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>0.009141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>type</td>\n",
       "      <td>ncbo_lda_test_21_results_2022-12-08.csv</td>\n",
       "      <td>0.024105</td>\n",
       "      <td>0.399209</td>\n",
       "      <td>0.045465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>type</td>\n",
       "      <td>ncbo_lda_train_21_results_2022-12-08.csv</td>\n",
       "      <td>0.031776</td>\n",
       "      <td>0.296527</td>\n",
       "      <td>0.057401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...</td>\n",
       "      <td>0.478951</td>\n",
       "      <td>0.443718</td>\n",
       "      <td>0.460662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_LDA_train_2022-12-07_15-04-23_em...</td>\n",
       "      <td>0.423714</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.412677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.359718</td>\n",
       "      <td>0.390211</td>\n",
       "      <td>0.374344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type</td>\n",
       "      <td>tagged_1_word_bertopic_lemmatize_nostopwords_d...</td>\n",
       "      <td>0.361691</td>\n",
       "      <td>0.377584</td>\n",
       "      <td>0.369467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agg_level                                               file  precision  \\\n",
       "8        cui  bertopic_ncbo_fulldata_lemmatize_nostopwords_d...   0.000106   \n",
       "10       cui  bertopic_ncbo_fulldata_lemmatize_nostopwords_d...   0.000106   \n",
       "12       cui            ncbo_lda_test_21_results_2022-12-08.csv   0.000000   \n",
       "14       cui           ncbo_lda_train_21_results_2022-12-08.csv   0.000034   \n",
       "4        cui  tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...   0.016789   \n",
       "6        cui  tagged_1_word_LDA_train_2022-12-07_15-04-23_em...   0.014899   \n",
       "0        cui  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.012911   \n",
       "2        cui  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.011797   \n",
       "9       type  bertopic_ncbo_fulldata_lemmatize_nostopwords_d...   0.004637   \n",
       "11      type  bertopic_ncbo_fulldata_lemmatize_nostopwords_d...   0.004613   \n",
       "13      type            ncbo_lda_test_21_results_2022-12-08.csv   0.024105   \n",
       "15      type           ncbo_lda_train_21_results_2022-12-08.csv   0.031776   \n",
       "5       type  tagged_1_word_LDA_test_2022-12-07_15-04-23_emb...   0.478951   \n",
       "7       type  tagged_1_word_LDA_train_2022-12-07_15-04-23_em...   0.423714   \n",
       "1       type  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.359718   \n",
       "3       type  tagged_1_word_bertopic_lemmatize_nostopwords_d...   0.361691   \n",
       "\n",
       "      recall        F1  \n",
       "8   0.029283  0.000212  \n",
       "10  0.024451  0.000211  \n",
       "12  0.000000  0.000000  \n",
       "14  0.000692  0.000064  \n",
       "4   0.026272  0.020486  \n",
       "6   0.022509  0.017930  \n",
       "0   0.019117  0.015413  \n",
       "2   0.017724  0.014166  \n",
       "9   0.574675  0.009200  \n",
       "11  0.497829  0.009141  \n",
       "13  0.399209  0.045465  \n",
       "15  0.296527  0.057401  \n",
       "5   0.443718  0.460662  \n",
       "7   0.402200  0.412677  \n",
       "1   0.390211  0.374344  \n",
       "3   0.377584  0.369467  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "for file in glob.glob('../results/bertopic_nbco/disambiguation/*disambiguation.csv') + glob.glob('../results/lda_ncbo/disambiguation/*'):\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[['PMID', 'disambiguation_fine_tuned_best_concept']]\n",
    "    df['disambiguation_fine_tuned_best_concept'] = df['disambiguation_fine_tuned_best_concept']\\\n",
    "        .apply(eval).apply(lambda x: list(x.values()))\n",
    "    df = df.explode('disambiguation_fine_tuned_best_concept')\n",
    "    df = df.merge(concepts_to_cuis, left_on='disambiguation_fine_tuned_best_concept', right_on='concept_name', how='left')\\\n",
    "        .drop('disambiguation_fine_tuned_best_concept', axis=1)\\\n",
    "        .merge(gt, how='left')\\\n",
    "        .rename({'CUIs': 'pred_cuis', 'true_CUIs': 'true_cuis'}, axis=1)\n",
    "    df['pred_cuis'] = df['pred_cuis'].apply(lambda x: [] if x != x else x)\n",
    "    df[['pred_type', 'true_type']] = df[['pred_cuis','true_cuis']].apply(change_cui_to_type, axis=1)\n",
    "    \n",
    "    TP_FN_FP_cuis = np.zeros((3,))\n",
    "    TP_FN_FP_types = np.zeros((3,))\n",
    "    for i, row in df.iterrows(): \n",
    "        TP_FN_FP_cuis += return_TP_FN_FP(row['pred_cuis'], row['true_cuis'])\n",
    "        TP_FN_FP_types += return_TP_FN_FP(row['pred_type'], row['true_type'])\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_cuis[0], TP_FN_FP_cuis[2])\n",
    "    recall_ = recall(TP_FN_FP_cuis[0], TP_FN_FP_cuis[1])\n",
    "    stats.append(('cui', os.path.basename(file), precision_, recall_, F1(precision_, recall_)))\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_types[0], TP_FN_FP_types[2])\n",
    "    recall_ = recall(TP_FN_FP_types[0], TP_FN_FP_types[1])\n",
    "    stats.append(('type', os.path.basename(file), precision_, recall_, F1(precision_, recall_)))\n",
    "stats = pd.DataFrame(stats, columns=['agg_level', 'file', 'precision', 'recall', 'F1'])\n",
    "stats.sort_values(['agg_level', 'file'])#.to_csv('../results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f102472",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_names = {'../results/bertopic_nbco/disambiguation\\\\bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_test_disambiguation.csv': 'bertopic_ncbo_test',\n",
    " '../results/bertopic_nbco/disambiguation\\\\bertopic_ncbo_fulldata_lemmatize_nostopwords_data_2022-11-30_12-09-18_train_disambiguation.csv': 'bertopic_ncbo_train',\n",
    " '../results/lda_ncbo/disambiguation\\\\ncbo_lda_test_21_results_2022-12-08.csv': 'lda_ncbo_test',\n",
    " '../results/lda_ncbo/disambiguation\\\\ncbo_lda_train_21_results_2022-12-08.csv': 'lda_ncbo_train',\n",
    " '..\\\\results\\\\emb_tagger\\\\tagged_1_word_bertopic_lemmatize_nostopwords_data_2022-11-28_19-41-48_test_emb_tagger_biobert.csv':'bertopic_emb_test',\n",
    " '..\\\\results\\\\emb_tagger\\\\tagged_1_word_bertopic_lemmatize_nostopwords_data_2022-11-28_19-41-48_train_emb_tagger_biobert.csv': 'bertopic_emb_train',\n",
    " '..\\\\results\\\\emb_tagger\\\\tagged_1_word_LDA_test_2022-12-07_15-04-23_emb_tagger_biobert.csv': 'lda_emb_test',\n",
    " '..\\\\results\\\\emb_tagger\\\\tagged_1_word_LDA_train_2022-12-07_15-04-23_emb_tagger_biobert.csv': 'lda_emb_train'}\n",
    "files_to_names = {os.path.basename(file): name for file, name in files_to_names.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "336bed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['file'] = stats['file'].map(files_to_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcfb71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['precision','recall','F1']: \n",
    "    stats[col] = stats[col].apply(lambda x: round(100*x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da5059f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[stats['agg_level'] != 'cui'].drop('agg_level',axis=1).sort_values(['file']).to_csv('../results/stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b430ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
