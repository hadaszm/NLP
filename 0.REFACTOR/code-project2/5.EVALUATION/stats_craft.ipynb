{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6186f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e95bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8391290",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_glob_regex = '../../0.RESULTS/embeddings/*_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec41667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(TP, FP): \n",
    "    return TP/(TP+FP)\n",
    "\n",
    "def recall(TP, FN): \n",
    "    return TP/(TP+FN)\n",
    "\n",
    "def F1(precision, recall):\n",
    "    return 2/(1/precision + 1/recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3c0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_TP_FN_FP(keywords, ground_truth):\n",
    "    keywords = set(keywords)\n",
    "    ground_truth = set(ground_truth)\n",
    "    TP = len(keywords.intersection(ground_truth) )\n",
    "    FN = len(keywords.difference(ground_truth))\n",
    "    FP = len(ground_truth.difference(keywords))\n",
    "    return np.array([TP, FN, FP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d33618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_list(pmid, pairs):\n",
    "    result = []\n",
    "    for pair in pairs:\n",
    "        result.append((pmid, pair[0], pair[1]))\n",
    "    return result\n",
    "\n",
    "def explode_df(df): \n",
    "    result = []\n",
    "    for i, row in df.iterrows(): \n",
    "        result += explode_list(row['PMID'], eval(row['ncbo_annotations_pairs']))\n",
    "    return pd.DataFrame(result, columns=['PMID', 'keyword', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e94ff6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_id(id_): \n",
    "    if ':' in id_:\n",
    "        id_ = id_.split(':')\n",
    "    else: \n",
    "        id_ = id_.split('_')\n",
    "    try:\n",
    "        id_[1] = int(id_[1])\n",
    "    except (ValueError, IndexError) as e: \n",
    "        pass\n",
    "    return tuple(id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62a6a8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MentionTextSegment</th>\n",
       "      <th>id</th>\n",
       "      <th>PMID</th>\n",
       "      <th>ontology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biological pigment</td>\n",
       "      <td>(chebi, 26130)</td>\n",
       "      <td>11532192</td>\n",
       "      <td>chebi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cation</td>\n",
       "      <td>(chebi, 36916)</td>\n",
       "      <td>11897010</td>\n",
       "      <td>chebi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ion</td>\n",
       "      <td>(chebi, 24870)</td>\n",
       "      <td>11897010</td>\n",
       "      <td>chebi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chromogenic compound</td>\n",
       "      <td>(chebi, 75050)</td>\n",
       "      <td>12079497</td>\n",
       "      <td>chebi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electron</td>\n",
       "      <td>(chebi, 10545)</td>\n",
       "      <td>12546709</td>\n",
       "      <td>chebi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MentionTextSegment              id      PMID ontology\n",
       "0    biological pigment  (chebi, 26130)  11532192    chebi\n",
       "1                cation  (chebi, 36916)  11897010    chebi\n",
       "2                   ion  (chebi, 24870)  11897010    chebi\n",
       "3  chromogenic compound  (chebi, 75050)  12079497    chebi\n",
       "4              electron  (chebi, 10545)  12546709    chebi"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = []\n",
    "for file in glob.glob('../0.RESULTS/preprocessing/*/annotations.csv'): \n",
    "    onto = os.path.basename(os.path.dirname(file))\n",
    "    if 'GO_' in onto:\n",
    "        onto = 'GO'\n",
    "    tmp = pd.read_csv(file)\n",
    "    tmp['ontology'] = onto.lower()\n",
    "    annotations.append(tmp)\n",
    "annotations = pd.concat(annotations).drop(['Unnamed: 0','StartIndex','EndIndex'],axis=1)\\\n",
    "    .rename({'EntityID': 'id'}, axis=1)\n",
    "annotations['id'] = annotations['id'].apply(lambda x: x.lower()).apply(process_id)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87c70c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chebi', 'cl', 'go', 'mop', 'ncbitaxon', 'pr', 'so', 'uberon'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(annotations['id'].apply(lambda x: x[0]).drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e3d13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>keyword</th>\n",
       "      <th>similarity_type</th>\n",
       "      <th>concept</th>\n",
       "      <th>id</th>\n",
       "      <th>ontology</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PMID, keyword, similarity_type, concept, id, ontology, keywords]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tags = pd.concat([pd.read_csv(file) for file in glob.glob('../0.RESULTS/emb_tagger/*')[1:]])\n",
    "all_tags[all_tags['id'].isin([\n",
    "'1058',\n",
    "'8620',\n",
    "'BFO_0000023',\n",
    "'BFO_0000034',\n",
    "'CARO_0000013',\n",
    "'ENVO_01000739',\n",
    "'FOODON_00003004',\n",
    "'MGI:1890498',\n",
    "'MONDO_0021140',\n",
    "'MONDO_0021152',\n",
    "'NCBITaxon_family', \n",
    "'UPHENO_0001001',\n",
    "'WBGene00003937',\n",
    "'WBGene00004950',\n",
    "'WBGene00006560',\n",
    "'WBGene00011828',\n",
    "'main.html?id=1591873',\n",
    "'main.html?id=2666',\n",
    "'main.html?id=620991'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "875d5549",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_groupped = annotations.groupby('PMID').apply(lambda x: \n",
    "                                 pd.Series({'true_ids': set(x['id'])}, index=['true_ids'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e2d4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "648fd034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bertopic_lemmatize_nostopwords_data_2023-01-17_23-06-45_keywords_10_min_topic_size_3_bertopic_cosine_tagged.csv</td>\n",
       "      <td>4.124802</td>\n",
       "      <td>8.210526</td>\n",
       "      <td>5.491024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bertopic_lemmatize_nostopwords_data_2023-01-17_23-06-45_keywords_10_min_topic_size_3_bertopic_distance_tagged.csv</td>\n",
       "      <td>4.442094</td>\n",
       "      <td>8.493428</td>\n",
       "      <td>5.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bertopic_lemmatize_nostopwords_data_2023-01-19_20-23-22_keywords_22_min_topic_size_6_bertopic_cosine_tagged.csv</td>\n",
       "      <td>7.350608</td>\n",
       "      <td>6.857425</td>\n",
       "      <td>7.095457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bertopic_lemmatize_nostopwords_data_2023-01-19_20-23-22_keywords_22_min_topic_size_6_bertopic_distance_tagged.csv</td>\n",
       "      <td>7.350608</td>\n",
       "      <td>6.790425</td>\n",
       "      <td>7.059421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lda_results_2023-01-17_22-31-53_keywords_10_topics_9_lda_cosine_tagged.csv</td>\n",
       "      <td>4.918033</td>\n",
       "      <td>9.707724</td>\n",
       "      <td>6.528607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lda_results_2023-01-17_22-31-53_keywords_10_topics_9_lda_distance_tagged.csv</td>\n",
       "      <td>5.182443</td>\n",
       "      <td>9.898990</td>\n",
       "      <td>6.803193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lda_results_2023-01-19_20-01-44_keywords_22_topics_7_lda_cosine_tagged.csv</td>\n",
       "      <td>5.552618</td>\n",
       "      <td>5.381855</td>\n",
       "      <td>5.465903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lda_results_2023-01-19_20-01-44_keywords_22_topics_7_lda_distance_tagged.csv</td>\n",
       "      <td>5.817028</td>\n",
       "      <td>5.522088</td>\n",
       "      <td>5.665722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                file  \\\n",
       "0    bertopic_lemmatize_nostopwords_data_2023-01-17_23-06-45_keywords_10_min_topic_size_3_bertopic_cosine_tagged.csv   \n",
       "1  bertopic_lemmatize_nostopwords_data_2023-01-17_23-06-45_keywords_10_min_topic_size_3_bertopic_distance_tagged.csv   \n",
       "2    bertopic_lemmatize_nostopwords_data_2023-01-19_20-23-22_keywords_22_min_topic_size_6_bertopic_cosine_tagged.csv   \n",
       "3  bertopic_lemmatize_nostopwords_data_2023-01-19_20-23-22_keywords_22_min_topic_size_6_bertopic_distance_tagged.csv   \n",
       "4                                         lda_results_2023-01-17_22-31-53_keywords_10_topics_9_lda_cosine_tagged.csv   \n",
       "5                                       lda_results_2023-01-17_22-31-53_keywords_10_topics_9_lda_distance_tagged.csv   \n",
       "6                                         lda_results_2023-01-19_20-01-44_keywords_22_topics_7_lda_cosine_tagged.csv   \n",
       "7                                       lda_results_2023-01-19_20-01-44_keywords_22_topics_7_lda_distance_tagged.csv   \n",
       "\n",
       "   precision    recall        F1  \n",
       "0   4.124802  8.210526  5.491024  \n",
       "1   4.442094  8.493428  5.833333  \n",
       "2   7.350608  6.857425  7.095457  \n",
       "3   7.350608  6.790425  7.059421  \n",
       "4   4.918033  9.707724  6.528607  \n",
       "5   5.182443  9.898990  6.803193  \n",
       "6   5.552618  5.381855  5.465903  \n",
       "7   5.817028  5.522088  5.665722  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = []\n",
    "for file in glob.glob('../0.RESULTS/emb_tagger/*'):\n",
    "    tagged = pd.read_csv(file)\n",
    "    tagged['id'] = tagged['id'].apply(lambda x: x.lower()).apply(process_id)\n",
    "    tagged_groupped = tagged.groupby('PMID').apply(lambda x: \n",
    "                                 pd.Series({'pred_ids': set(x['id'])}, index=['pred_ids'])).reset_index()\n",
    "    merged = tagged_groupped.merge(annotations_groupped,how='outer')\n",
    "    \n",
    "    \n",
    "    TP_FN_FP_ids = np.zeros((3,))\n",
    "    for i, row in merged.iterrows(): \n",
    "        TP_FN_FP_ids += return_TP_FN_FP(row['pred_ids'], row['true_ids'])\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_ids[0],TP_FN_FP_ids[2])\n",
    "    recall_ = recall(TP_FN_FP_ids[0], TP_FN_FP_ids[1])\n",
    "    stats.append((os.path.basename(file), precision_*100, recall_*100, 100*F1(precision_, recall_)))\n",
    "pd.DataFrame(stats, columns=['file', 'precision', 'recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86aac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontologies_mappings = pd.concat([pd.read_csv(file) for file in glob.glob('../0.RESULTS/preprocessing/_ontologies_mappings/*')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b5670f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ncbo_concepts_used = pd.concat([pd.read_csv(file) for file in glob.glob('../0.RESULTS/disambiguation/*')])\n",
    "text_to_id = dict()\n",
    "for elem in sum(all_ncbo_concepts_used['ncbo_annotations'].apply(eval), []):\n",
    "    id_ = elem['annotatedClass']['@id'].split('/')[-1]\n",
    "    for annotation in elem['annotations']:\n",
    "        text_to_id[annotation['text'].lower()] = id_\n",
    "all_ncbo_concepts_used = {elem['annotatedClass']['@id'].split('/')[-1] for elem in sum(all_ncbo_concepts_used['ncbo_annotations'].apply(eval), [])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e999dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_concepts = ontologies_mappings[ontologies_mappings['id'].isin(all_ncbo_concepts_used)].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1704ded8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T008', 'T016', 'T025', 'T126', 'T192'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ncbo_concepts_used.difference(filtered_concepts['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2e5d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontologies_mappings['label'] = ontologies_mappings['label'].apply(lambda x: x.lower())\n",
    "label_to_ids = ontologies_mappings.groupby('label').apply(lambda x: list(set(x['id']))).reset_index().rename({0: 'ids'}, axis=1)\n",
    "label_to_ids = dict(zip(label_to_ids['label'], label_to_ids['ids']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2fb9756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_id(id_): \n",
    "    if ':' in id_:\n",
    "        id_ = id_.split(':')\n",
    "    else: \n",
    "        id_ = id_.split('_')\n",
    "    try:\n",
    "        id_[1] = int(id_[1])\n",
    "    except (ValueError, IndexError) as e: \n",
    "        pass\n",
    "    return tuple(id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "972d0adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     1338\n",
      "label    1338\n",
      "id       1338\n",
      "dtype: int64\n",
      "PMID     1338\n",
      "label    1338\n",
      "id       1338\n",
      "dtype: int64\n",
      "PMID     1338\n",
      "label    1338\n",
      "id       1229\n",
      "dtype: int64\n",
      "PMID     1338\n",
      "label    1338\n",
      "id       1338\n",
      "dtype: int64\n",
      "PMID     1237\n",
      "label    1237\n",
      "id       1237\n",
      "dtype: int64\n",
      "PMID     1237\n",
      "label    1237\n",
      "id       1237\n",
      "dtype: int64\n",
      "PMID     1237\n",
      "label    1237\n",
      "id       1152\n",
      "dtype: int64\n",
      "PMID     1237\n",
      "label    1237\n",
      "id       1237\n",
      "dtype: int64\n",
      "PMID     710\n",
      "label    710\n",
      "id       705\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kszku\\AppData\\Local\\Temp\\ipykernel_21816\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     710\n",
      "label    710\n",
      "id       705\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kszku\\AppData\\Local\\Temp\\ipykernel_21816\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     710\n",
      "label    710\n",
      "id       705\n",
      "dtype: int64\n",
      "PMID     710\n",
      "label    710\n",
      "id       705\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kszku\\AppData\\Local\\Temp\\ipykernel_21816\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     677\n",
      "label    677\n",
      "id       677\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kszku\\AppData\\Local\\Temp\\ipykernel_21816\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     677\n",
      "label    677\n",
      "id       677\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kszku\\AppData\\Local\\Temp\\ipykernel_21816\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID     677\n",
      "label    677\n",
      "id       607\n",
      "dtype: int64\n",
      "PMID     677\n",
      "label    677\n",
      "id       677\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kszku\\AppData\\Local\\Temp\\ipykernel_21816\\269410256.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 2/(1/precision + 1/recall)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bertopic_lemmatize_nostopwords_data_2023-01-17_23-06-45_keywords_10_min_topic_size_3_bertopic_cosine_tagged.csv</td>\n",
       "      <td>4.124802</td>\n",
       "      <td>8.210526</td>\n",
       "      <td>5.491024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bertopic_lemmatize_nostopwords_data_2023-01-17_23-06-45_keywords_10_min_topic_size_3_bertopic_distance_tagged.csv</td>\n",
       "      <td>4.442094</td>\n",
       "      <td>8.493428</td>\n",
       "      <td>5.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bertopic_lemmatize_nostopwords_data_2023-01-19_20-23-22_keywords_22_min_topic_size_6_bertopic_cosine_tagged.csv</td>\n",
       "      <td>7.350608</td>\n",
       "      <td>6.857425</td>\n",
       "      <td>7.095457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bertopic_lemmatize_nostopwords_data_2023-01-19_20-23-22_keywords_22_min_topic_size_6_bertopic_distance_tagged.csv</td>\n",
       "      <td>7.350608</td>\n",
       "      <td>6.790425</td>\n",
       "      <td>7.059421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lda_results_2023-01-17_22-31-53_keywords_10_topics_9_lda_cosine_tagged.csv</td>\n",
       "      <td>4.918033</td>\n",
       "      <td>9.707724</td>\n",
       "      <td>6.528607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lda_results_2023-01-17_22-31-53_keywords_10_topics_9_lda_distance_tagged.csv</td>\n",
       "      <td>5.182443</td>\n",
       "      <td>9.898990</td>\n",
       "      <td>6.803193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lda_results_2023-01-19_20-01-44_keywords_22_topics_7_lda_cosine_tagged.csv</td>\n",
       "      <td>5.552618</td>\n",
       "      <td>5.381855</td>\n",
       "      <td>5.465903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lda_results_2023-01-19_20-01-44_keywords_22_topics_7_lda_distance_tagged.csv</td>\n",
       "      <td>5.817028</td>\n",
       "      <td>5.522088</td>\n",
       "      <td>5.665722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bertopic_keywords_22_min_topic_size_6_ncbo_2023_01_19_22_02_16_no_sorting_no_weighting_no_forcing.csv</td>\n",
       "      <td>0.021153</td>\n",
       "      <td>0.099256</td>\n",
       "      <td>0.034874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bertopic_keywords_22_min_topic_size_6_ncbo_2023_01_19_22_02_16_sorting_no_weighting_no_forcing.csv</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.067885</td>\n",
       "      <td>0.022867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bertopic_keywords_22_min_topic_size_6_ncbo_2023_01_19_22_02_16_sorting_weighting_forcing.csv</td>\n",
       "      <td>0.070333</td>\n",
       "      <td>0.103421</td>\n",
       "      <td>0.083727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bertopic_keywords_22_min_topic_size_6_ncbo_2023_01_19_22_02_16_sorting_weighting_no_forcing.csv</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.067885</td>\n",
       "      <td>0.022867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bertopic_keywords_22_topics_7_ncbo_2023_01_19_22_09_22_no_sorting_no_weighting_no_forcing.csv</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.076596</td>\n",
       "      <td>0.030496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bertopic_keywords_22_topics_7_ncbo_2023_01_19_22_09_22_sorting_no_weighting_no_forcing.csv</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.076596</td>\n",
       "      <td>0.030496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bertopic_keywords_22_topics_7_ncbo_2023_01_19_22_09_22_sorting_weighting_forcing.csv</td>\n",
       "      <td>0.050238</td>\n",
       "      <td>0.081545</td>\n",
       "      <td>0.062173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bertopic_keywords_22_topics_7_ncbo_2023_01_19_22_09_22_sorting_weighting_no_forcing.csv</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.076596</td>\n",
       "      <td>0.030496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bertopic_ncbo_2023_01_18_21_51_08_keywords_10_min_topic_size_3_no_sorting_no_weighting_no_forcing.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bertopic_ncbo_2023_01_18_21_51_08_keywords_10_min_topic_size_3_sorting_no_weighting_no_forcing.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bertopic_ncbo_2023_01_18_21_51_08_keywords_10_min_topic_size_3_sorting_weighting_forcing.csv</td>\n",
       "      <td>0.054469</td>\n",
       "      <td>0.158462</td>\n",
       "      <td>0.081070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bertopic_ncbo_2023_01_18_21_51_08_keywords_10_min_topic_size_3_sorting_weighting_no_forcing.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lda_ncbo_2023_01_18_22_54_12_keywords_10_topics_9_no_sorting_no_weighting_no_forcing.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lda_ncbo_2023_01_18_22_54_12_keywords_10_topics_9_sorting_no_weighting_no_forcing.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lda_ncbo_2023_01_18_22_54_12_keywords_10_topics_9_sorting_weighting_forcing.csv</td>\n",
       "      <td>0.047594</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.068156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lda_ncbo_2023_01_18_22_54_12_keywords_10_topics_9_sorting_weighting_no_forcing.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 file  \\\n",
       "0     bertopic_lemmatize_nostopwords_data_2023-01-17_23-06-45_keywords_10_min_topic_size_3_bertopic_cosine_tagged.csv   \n",
       "1   bertopic_lemmatize_nostopwords_data_2023-01-17_23-06-45_keywords_10_min_topic_size_3_bertopic_distance_tagged.csv   \n",
       "2     bertopic_lemmatize_nostopwords_data_2023-01-19_20-23-22_keywords_22_min_topic_size_6_bertopic_cosine_tagged.csv   \n",
       "3   bertopic_lemmatize_nostopwords_data_2023-01-19_20-23-22_keywords_22_min_topic_size_6_bertopic_distance_tagged.csv   \n",
       "4                                          lda_results_2023-01-17_22-31-53_keywords_10_topics_9_lda_cosine_tagged.csv   \n",
       "5                                        lda_results_2023-01-17_22-31-53_keywords_10_topics_9_lda_distance_tagged.csv   \n",
       "6                                          lda_results_2023-01-19_20-01-44_keywords_22_topics_7_lda_cosine_tagged.csv   \n",
       "7                                        lda_results_2023-01-19_20-01-44_keywords_22_topics_7_lda_distance_tagged.csv   \n",
       "8               bertopic_keywords_22_min_topic_size_6_ncbo_2023_01_19_22_02_16_no_sorting_no_weighting_no_forcing.csv   \n",
       "9                  bertopic_keywords_22_min_topic_size_6_ncbo_2023_01_19_22_02_16_sorting_no_weighting_no_forcing.csv   \n",
       "10                       bertopic_keywords_22_min_topic_size_6_ncbo_2023_01_19_22_02_16_sorting_weighting_forcing.csv   \n",
       "11                    bertopic_keywords_22_min_topic_size_6_ncbo_2023_01_19_22_02_16_sorting_weighting_no_forcing.csv   \n",
       "12                      bertopic_keywords_22_topics_7_ncbo_2023_01_19_22_09_22_no_sorting_no_weighting_no_forcing.csv   \n",
       "13                         bertopic_keywords_22_topics_7_ncbo_2023_01_19_22_09_22_sorting_no_weighting_no_forcing.csv   \n",
       "14                               bertopic_keywords_22_topics_7_ncbo_2023_01_19_22_09_22_sorting_weighting_forcing.csv   \n",
       "15                            bertopic_keywords_22_topics_7_ncbo_2023_01_19_22_09_22_sorting_weighting_no_forcing.csv   \n",
       "16              bertopic_ncbo_2023_01_18_21_51_08_keywords_10_min_topic_size_3_no_sorting_no_weighting_no_forcing.csv   \n",
       "17                 bertopic_ncbo_2023_01_18_21_51_08_keywords_10_min_topic_size_3_sorting_no_weighting_no_forcing.csv   \n",
       "18                       bertopic_ncbo_2023_01_18_21_51_08_keywords_10_min_topic_size_3_sorting_weighting_forcing.csv   \n",
       "19                    bertopic_ncbo_2023_01_18_21_51_08_keywords_10_min_topic_size_3_sorting_weighting_no_forcing.csv   \n",
       "20                           lda_ncbo_2023_01_18_22_54_12_keywords_10_topics_9_no_sorting_no_weighting_no_forcing.csv   \n",
       "21                              lda_ncbo_2023_01_18_22_54_12_keywords_10_topics_9_sorting_no_weighting_no_forcing.csv   \n",
       "22                                    lda_ncbo_2023_01_18_22_54_12_keywords_10_topics_9_sorting_weighting_forcing.csv   \n",
       "23                                 lda_ncbo_2023_01_18_22_54_12_keywords_10_topics_9_sorting_weighting_no_forcing.csv   \n",
       "\n",
       "    precision    recall        F1  \n",
       "0    4.124802  8.210526  5.491024  \n",
       "1    4.442094  8.493428  5.833333  \n",
       "2    7.350608  6.857425  7.095457  \n",
       "3    7.350608  6.790425  7.059421  \n",
       "4    4.918033  9.707724  6.528607  \n",
       "5    5.182443  9.898990  6.803193  \n",
       "6    5.552618  5.381855  5.465903  \n",
       "7    5.817028  5.522088  5.665722  \n",
       "8    0.021153  0.099256  0.034874  \n",
       "9    0.013749  0.067885  0.022867  \n",
       "10   0.070333  0.103421  0.083727  \n",
       "11   0.013749  0.067885  0.022867  \n",
       "12   0.019038  0.076596  0.030496  \n",
       "13   0.019038  0.076596  0.030496  \n",
       "14   0.050238  0.081545  0.062173  \n",
       "15   0.019038  0.076596  0.030496  \n",
       "16   0.000000  0.000000  0.000000  \n",
       "17   0.000000  0.000000  0.000000  \n",
       "18   0.054469  0.158462  0.081070  \n",
       "19   0.000000  0.000000  0.000000  \n",
       "20   0.000000  0.000000  0.000000  \n",
       "21   0.000000  0.000000  0.000000  \n",
       "22   0.047594  0.120000  0.068156  \n",
       "23   0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = stats[:8]\n",
    "for file in glob.glob('../0.RESULTS/disambiguation/*'):\n",
    "    dis = pd.read_csv(file) \n",
    "    dis['disambiguation_best_concept'] = dis['disambiguation_best_concept'].apply(eval).apply(lambda x: [v[0].lower() for v in x.values()])\n",
    "    dis = dis[['PMID', 'disambiguation_best_concept']].explode('disambiguation_best_concept')\\\n",
    "        .rename({'disambiguation_best_concept': 'label'}, axis=1)\n",
    "    \n",
    "    dis['id'] = dis['label'].map(label_to_ids)\n",
    "    print(dis.count())\n",
    "    dis['id'] = dis['id'].apply(lambda x: x if x == x else [])\n",
    "\n",
    "    dis['id'] = dis['id'].apply(lambda x: [process_id(elem.lower()) for elem in x])\n",
    "    dis = dis.groupby('PMID').apply(lambda x: \n",
    "                     pd.Series({'pred_ids': set(sum(x['id'], []))}, index=['pred_ids'])).reset_index()\n",
    "    merged = dis.merge(annotations_groupped,on=['PMID'], how='outer')\n",
    "    \n",
    "    TP_FN_FP_ids = np.zeros((3,))\n",
    "    for i, row in merged.iterrows(): \n",
    "        TP_FN_FP_ids += return_TP_FN_FP(row['pred_ids'], row['true_ids'])\n",
    "    \n",
    "    precision_ = precision(TP_FN_FP_ids[0],TP_FN_FP_ids[2])\n",
    "    recall_ = recall(TP_FN_FP_ids[0], TP_FN_FP_ids[1])\n",
    "    stats.append((os.path.basename(file), precision_, recall_, F1(precision_, recall_)))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(stats, columns=['file', 'precision', 'recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8daeedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(stats, columns=['file', 'precision', 'recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2337107",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../0.RESULTS/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6be8d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in results.columns[1:]: \n",
    "    results[col] = results[col].apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "845b2ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['file'].apply(lambda x: 'no_forcing' not in x)].to_csv('../0.RESULTS/results_without_no_forcing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c013e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8220f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2046c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87a028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437eb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e1fc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
