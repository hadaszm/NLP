{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "import datetime\n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic BertTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions/definitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "train_data_path = '../data/titles_and_abstracts_processed_train.csv'\n",
    "test_data_path = '../data/titles_and_abstracts_processed_test.csv'\n",
    "models_path = '../models/' \n",
    "raw_data_results_path = '../results/bertopic/raw_data'\n",
    "processed_data_results_path = '../results/bertopic/processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_now_str():\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_strings_to_arrays(df, col_names = ['tokenized_sentences', 'tokenized_words', 'tokenized_words_processed']):\n",
    "    for col in col_names:\n",
    "        df[col] = df[col].apply(eval)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic BertTopic keyword extraction\n",
    "def train_transform_save(train_data, model_save_name):\n",
    "    \n",
    "    # train transform\n",
    "    topic_model = BERTopic()\n",
    "    topics, probs = topic_model.fit_transform(train_data.values)\n",
    "\n",
    "    # save model\n",
    "    topic_model.save(model_save_name)\n",
    "\n",
    "    return topic_model, topics, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transform_save(data, model_save_name, results_path):\n",
    "\n",
    "    # load model\n",
    "    loaded_model = BERTopic.load(model_save_name)\n",
    "\n",
    "    # transform for data \n",
    "    samples_topics, samples_probs = loaded_model.transform(data.values)\n",
    "    res_df = pd.DataFrame({\n",
    "        'PMID': np.unique(data.PMID),\n",
    "        'topic_number': samples_topics,\n",
    "        'topic_probs': samples_probs,\n",
    "        \"topic_keywords\": [loaded_model.get_topic(topic_number) for topic_number in samples_topics]\n",
    "    })\n",
    "    res_df.to_csv(results_path)\n",
    "    return loaded_model, res_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw data (without steming and stop words removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [207], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_full_data \u001b[39m=\u001b[39m transform_strings_to_arrays(pd\u001b[39m.\u001b[39;49mread_csv(train_data_path))\n\u001b[0;32m      2\u001b[0m test_full_data \u001b[39m=\u001b[39m transform_strings_to_arrays(pd\u001b[39m.\u001b[39mread_csv(test_data_path))\n\u001b[0;32m      4\u001b[0m train_data \u001b[39m=\u001b[39m train_full_data\u001b[39m.\u001b[39mgroupby(by \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mPMID\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39m'\u001b[39m\u001b[39mtokenized_words_processed\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39magg(\u001b[39mlambda\u001b[39;00m x: \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(x\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m x\u001b[39m.\u001b[39mvalues[\u001b[39m1\u001b[39m]))\n",
      "Cell \u001b[1;32mIn [202], line 3\u001b[0m, in \u001b[0;36mtransform_strings_to_arrays\u001b[1;34m(df, col_names)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform_strings_to_arrays\u001b[39m(df, col_names \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mtokenized_sentences\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtokenized_words\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtokenized_words_processed\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m col_names:\n\u001b[1;32m----> 3\u001b[0m         df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39;49mapply(\u001b[39meval\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\gozde\\.conda\\envs\\nlp\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\gozde\\.conda\\envs\\nlp\\lib\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\gozde\\.conda\\envs\\nlp\\lib\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\gozde\\.conda\\envs\\nlp\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_full_data = transform_strings_to_arrays(pd.read_csv(train_data_path))\n",
    "test_full_data = transform_strings_to_arrays(pd.read_csv(test_data_path))\n",
    "\n",
    "train_data = train_full_data.groupby(by = ['PMID'])['tokenized_words_processed'].agg(lambda x: ' '.join(x.values[0] + x.values[1]))\n",
    "test_data = test_full_data.groupby(by = ['PMID'])['tokenized_words_processed'].agg(lambda x: ' '.join(x.values[0] + x.values[1]))\n",
    "\n",
    "model_save_name = os.path.join(models_path, f'berttopic_raw_data_{get_now_str()}')\n",
    "results_path = \n",
    "\n",
    "topic_model, topics, probs = train_transform_save(train_data, model_save_name)\n",
    "loaded_model, res_df = load_transform_save(train_data, model_save_name, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DCTN4 as a modifier of chronic Pseudomonas aeruginosa infection in cystic fibrosis. Pseudomonas aeruginosa (Pa) infection in cystic fibrosis (CF) patients is associated with worse long-term pulmonary disease and shorter survival, and chronic Pa infection (CPA) is associated with reduced lung function, faster rate of lung decline, increased rates of exacerbations and shorter survival. By using exome sequencing and extreme phenotype design, it was recently shown that isoforms of dynactin 4 (DCTN4) may influence Pa infection in CF, leading to worse respiratory disease. The purpose of this study was to investigate the role of DCTN4 missense variants on Pa infection incidence, age at first Pa infection and chronic Pa infection incidence in a cohort of adult CF patients from a single centre. Polymerase chain reaction and direct sequencing were used to screen DNA samples for DCTN4 variants. A total of 121 adult CF patients from the Cochin Hospital CF centre have been included, all of them carrying two CFTR defects: 103 developed at least 1 pulmonary infection with Pa, and 68 patients of them had CPA. DCTN4 variants were identified in 24% (29/121) CF patients with Pa infection and in only 17% (3/18) CF patients with no Pa infection. Of the patients with CPA, 29% (20/68) had DCTN4 missense variants vs 23% (8/35) in patients without CPA. Interestingly, p.Tyr263Cys tend to be more frequently observed in CF patients with CPA than in patients without CPA (4/68 vs 0/35), and DCTN4 missense variants tend to be more frequent in male CF patients with CPA bearing two class II mutations than in male CF patients without CPA bearing two class II mutations (P = 0.06). Our observations reinforce that DCTN4 missense variants, especially p.Tyr263Cys, may be involved in the pathogenesis of CPA in male CF.'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta_content_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic BertTopic keyword extraction\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(ta_content_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1343</td>\n",
       "      <td>-1_the_of_and_in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>0_health_care_to_and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>1_brain_to_the_in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>2_and_diabetes_vitamin_obesity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>3_cancer_cell_expression_cells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>59</td>\n",
       "      <td>11</td>\n",
       "      <td>59_asthma_allergic_medicine_sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>60_breast_cancer_bc_er</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>61_cardiac_mnk1_differentiation_bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>62_water_metal_dwtr_cu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>63_flap_nasal_ihcc_acc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                 Name\n",
       "0      -1   1343                     -1_the_of_and_in\n",
       "1       0    292                 0_health_care_to_and\n",
       "2       1    138                    1_brain_to_the_in\n",
       "3       2    119       2_and_diabetes_vitamin_obesity\n",
       "4       3     92       3_cancer_cell_expression_cells\n",
       "..    ...    ...                                  ...\n",
       "60     59     11       59_asthma_allergic_medicine_sa\n",
       "61     60     11               60_breast_cancer_bc_er\n",
       "62     61     10  61_cardiac_mnk1_differentiation_bio\n",
       "63     62     10               62_water_metal_dwtr_cu\n",
       "64     63     10               63_flap_nasal_ihcc_acc\n",
       "\n",
       "[65 rows x 3 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example \n",
    "i = 11\n",
    "pmid = train_data.iloc[i].PMID\n",
    "doc = '. '.join(train_data[train_data.PMID == pmid]['Content'].values)\n",
    "doc_topic = topics[i]\n",
    "doc_prob = probs[i]\n",
    "topic_info = topic_model.get_topic_info(doc_topic)\n",
    "topic_words = topic_model.get_topic(doc_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Promoting lifestyle behaviour change and well-being in hospital patients: a pilot study of an evidence-based psychological intervention. Lifestyle risk behaviours show an inverse social gradient, clustering in vulnerable groups. We designed and piloted an intervention to address barriers to lifestyle behaviour change among hospital patients. We designed our intervention using effective components of behaviour change interventions informed by psychological theory. Delivered by a health psychologist based at the Royal Free London NHS Foundation Trust, the 4-week intervention included detailed baseline assessment, personalized goal setting, psychological skills development, motivation support and referral to community services. Primary outcomes were feasibility and patient acceptability. We also evaluated changes to health and well-being. From 1 July 2013 to 31 September 2014, 686 patients were referred, 338 (49.3%) attended a first appointment and 172 (25.1%) completed follow-up. Furthermore, 72.1% of attenders were female with the median age 55 years and poor self-reported baseline health. After 4 weeks, self-efficacy, health and well-being scores significantly improved: 63% of lifestyle goals and 89% of health management goals were fully achieved; 58% of referrals to community lifestyle behaviour change services and 79% of referrals to other services (e.g. Citizen's Advice Bureau) were accepted; 99% were satisfied / very satisfied with the service. Our hospital-based intervention was feasible, acceptable and showed preliminary health and well-being gains.\""
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>4_species_the_of_and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                  Name\n",
       "0      4     67  4_species_the_of_and"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('species', 0.04094609274655893),\n",
       " ('the', 0.015919871735481973),\n",
       " ('of', 0.01407421291845833),\n",
       " ('and', 0.012802701613979894),\n",
       " ('forests', 0.012224788239035477),\n",
       " ('we', 0.012009514487563176),\n",
       " ('to', 0.011480034706860086),\n",
       " ('in', 0.011351481571335607),\n",
       " ('that', 0.011224663898045432),\n",
       " ('climate', 0.011025328387382053)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_save_name = os.path.join(models_path, f'berttopic_raw_content_{get_now_str()}')\n",
    "topic_model.save(model_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "loaded_model = BERTopic.load(model_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform data both training and test\n",
    "input_data = transform_strings_to_arrays(pd.read_csv(train_data_path))\n",
    "model = loaded_model\n",
    "save_path = os.path.join(results_path, f'{model_save_name}_test.csv')\n",
    "\n",
    "\n",
    "samples_list = input_data.groupby(by = ['PMID'])['tokenized_words_processed'].agg(lambda x: ' '.join(x.values[0] + x.values[1])).values\n",
    "\n",
    "samples_topics, samples_probs = model.transform(samples_list)\n",
    "res_df = pd.DataFrame({\n",
    "    'PMID': np.unique(input_data.PMID),\n",
    "    'topic_number': samples_topics,\n",
    "    \"topic_keywords\": [model.get_topic(topic_number) for topic_number in samples_topics]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>topic_number</th>\n",
       "      <th>topic_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25763772</td>\n",
       "      <td>-1</td>\n",
       "      <td>[(the, 0.013610109100331086), (of, 0.013344696...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25847295</td>\n",
       "      <td>-1</td>\n",
       "      <td>[(the, 0.013610109100331086), (of, 0.013344696...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26316050</td>\n",
       "      <td>-1</td>\n",
       "      <td>[(the, 0.013610109100331086), (of, 0.013344696...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26406200</td>\n",
       "      <td>14</td>\n",
       "      <td>[(walking, 0.023270379588251042), (players, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26424709</td>\n",
       "      <td>0</td>\n",
       "      <td>[(health, 0.01563368814463759), (care, 0.01416...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>28549399</td>\n",
       "      <td>0</td>\n",
       "      <td>[(health, 0.01563368814463759), (care, 0.01416...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>28549760</td>\n",
       "      <td>2</td>\n",
       "      <td>[(and, 0.015258906726062352), (diabetes, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>28550154</td>\n",
       "      <td>36</td>\n",
       "      <td>[(detection, 0.04332267580859146), (quantum, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>28550348</td>\n",
       "      <td>0</td>\n",
       "      <td>[(health, 0.01563368814463759), (care, 0.01416...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512</th>\n",
       "      <td>28550521</td>\n",
       "      <td>-1</td>\n",
       "      <td>[(the, 0.013610109100331086), (of, 0.013344696...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3513 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PMID  topic_number  \\\n",
       "0     25763772            -1   \n",
       "1     25847295            -1   \n",
       "2     26316050            -1   \n",
       "3     26406200            14   \n",
       "4     26424709             0   \n",
       "...        ...           ...   \n",
       "3508  28549399             0   \n",
       "3509  28549760             2   \n",
       "3510  28550154            36   \n",
       "3511  28550348             0   \n",
       "3512  28550521            -1   \n",
       "\n",
       "                                         topic_keywords  \n",
       "0     [(the, 0.013610109100331086), (of, 0.013344696...  \n",
       "1     [(the, 0.013610109100331086), (of, 0.013344696...  \n",
       "2     [(the, 0.013610109100331086), (of, 0.013344696...  \n",
       "3     [(walking, 0.023270379588251042), (players, 0....  \n",
       "4     [(health, 0.01563368814463759), (care, 0.01416...  \n",
       "...                                                 ...  \n",
       "3508  [(health, 0.01563368814463759), (care, 0.01416...  \n",
       "3509  [(and, 0.015258906726062352), (diabetes, 0.015...  \n",
       "3510  [(detection, 0.04332267580859146), (quantum, 0...  \n",
       "3511  [(health, 0.01563368814463759), (care, 0.01416...  \n",
       "3512  [(the, 0.013610109100331086), (of, 0.013344696...  \n",
       "\n",
       "[3513 rows x 3 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Content</th>\n",
       "      <th>tokenized_sentences</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>tokenized_words_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25763772</td>\n",
       "      <td>t</td>\n",
       "      <td>DCTN4 as a modifier of chronic Pseudomonas aer...</td>\n",
       "      <td>['DCTN4 as a modifier of chronic Pseudomonas a...</td>\n",
       "      <td>[['DCTN4', 'as', 'a', 'modifier', 'of', 'chron...</td>\n",
       "      <td>['dctn4', 'modifi', 'chronic', 'pseudomona', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25763772</td>\n",
       "      <td>a</td>\n",
       "      <td>Pseudomonas aeruginosa (Pa) infection in cysti...</td>\n",
       "      <td>['Pseudomonas aeruginosa (Pa) infection in cys...</td>\n",
       "      <td>[['Pseudomonas', 'aeruginosa', '(', 'Pa', ')',...</td>\n",
       "      <td>['pseudomona', 'aeruginosa', 'infect', 'cystic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25847295</td>\n",
       "      <td>t</td>\n",
       "      <td>Nonylphenol diethoxylate inhibits apoptosis in...</td>\n",
       "      <td>['Nonylphenol diethoxylate inhibits apoptosis ...</td>\n",
       "      <td>[['Nonylphenol', 'diethoxylate', 'inhibits', '...</td>\n",
       "      <td>['nonylphenol', 'diethoxyl', 'inhibit', 'apopt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25847295</td>\n",
       "      <td>a</td>\n",
       "      <td>Nonylphenol and short-chain nonylphenol ethoxy...</td>\n",
       "      <td>['Nonylphenol and short-chain nonylphenol etho...</td>\n",
       "      <td>[['Nonylphenol', 'and', 'short-chain', 'nonylp...</td>\n",
       "      <td>['nonylphenol', 'nonylphenol', 'ethoxyl', 'np2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26316050</td>\n",
       "      <td>t</td>\n",
       "      <td>Prevascularized silicon membranes for the enha...</td>\n",
       "      <td>['Prevascularized silicon membranes for the en...</td>\n",
       "      <td>[['Prevascularized', 'silicon', 'membranes', '...</td>\n",
       "      <td>['prevascular', 'silicon', 'membran', 'enhanc'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>28550154</td>\n",
       "      <td>a</td>\n",
       "      <td>The nanoparticles (NPs) of hemoglobin (Hb) wer...</td>\n",
       "      <td>['The nanoparticles (NPs) of hemoglobin (Hb) w...</td>\n",
       "      <td>[['The', 'nanoparticles', '(', 'NPs', ')', 'of...</td>\n",
       "      <td>['nanoparticl', 'np', 'hemoglobin', 'hb', 'pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>28550348</td>\n",
       "      <td>t</td>\n",
       "      <td>Medication regimen complexity and prevalence o...</td>\n",
       "      <td>['Medication regimen complexity and prevalence...</td>\n",
       "      <td>[['Medication', 'regimen', 'complexity', 'and'...</td>\n",
       "      <td>['medic', 'regimen', 'complex', 'preval', 'pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>28550348</td>\n",
       "      <td>a</td>\n",
       "      <td>Background There is a relative paucity of info...</td>\n",
       "      <td>['Background There is a relative paucity of in...</td>\n",
       "      <td>[['Background', 'There', 'is', 'a', 'relative'...</td>\n",
       "      <td>['background', 'rel', 'pauciti', 'inform', 'ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>28550521</td>\n",
       "      <td>t</td>\n",
       "      <td>Assessment of periodontal bone level revisited...</td>\n",
       "      <td>['Assessment of periodontal bone level revisit...</td>\n",
       "      <td>[['Assessment', 'of', 'periodontal', 'bone', '...</td>\n",
       "      <td>['assess', 'periodont', 'bone', 'level', 'revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>28550521</td>\n",
       "      <td>a</td>\n",
       "      <td>The accuracy of analogue and especially digita...</td>\n",
       "      <td>['The accuracy of analogue and especially digi...</td>\n",
       "      <td>[['The', 'accuracy', 'of', 'analogue', 'and', ...</td>\n",
       "      <td>['accuraci', 'analogu', 'especi', 'digit', 'ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7026 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PMID Type                                            Content  \\\n",
       "0     25763772    t  DCTN4 as a modifier of chronic Pseudomonas aer...   \n",
       "1     25763772    a  Pseudomonas aeruginosa (Pa) infection in cysti...   \n",
       "2     25847295    t  Nonylphenol diethoxylate inhibits apoptosis in...   \n",
       "3     25847295    a  Nonylphenol and short-chain nonylphenol ethoxy...   \n",
       "4     26316050    t  Prevascularized silicon membranes for the enha...   \n",
       "...        ...  ...                                                ...   \n",
       "7021  28550154    a  The nanoparticles (NPs) of hemoglobin (Hb) wer...   \n",
       "7022  28550348    t  Medication regimen complexity and prevalence o...   \n",
       "7023  28550348    a  Background There is a relative paucity of info...   \n",
       "7024  28550521    t  Assessment of periodontal bone level revisited...   \n",
       "7025  28550521    a  The accuracy of analogue and especially digita...   \n",
       "\n",
       "                                    tokenized_sentences  \\\n",
       "0     ['DCTN4 as a modifier of chronic Pseudomonas a...   \n",
       "1     ['Pseudomonas aeruginosa (Pa) infection in cys...   \n",
       "2     ['Nonylphenol diethoxylate inhibits apoptosis ...   \n",
       "3     ['Nonylphenol and short-chain nonylphenol etho...   \n",
       "4     ['Prevascularized silicon membranes for the en...   \n",
       "...                                                 ...   \n",
       "7021  ['The nanoparticles (NPs) of hemoglobin (Hb) w...   \n",
       "7022  ['Medication regimen complexity and prevalence...   \n",
       "7023  ['Background There is a relative paucity of in...   \n",
       "7024  ['Assessment of periodontal bone level revisit...   \n",
       "7025  ['The accuracy of analogue and especially digi...   \n",
       "\n",
       "                                        tokenized_words  \\\n",
       "0     [['DCTN4', 'as', 'a', 'modifier', 'of', 'chron...   \n",
       "1     [['Pseudomonas', 'aeruginosa', '(', 'Pa', ')',...   \n",
       "2     [['Nonylphenol', 'diethoxylate', 'inhibits', '...   \n",
       "3     [['Nonylphenol', 'and', 'short-chain', 'nonylp...   \n",
       "4     [['Prevascularized', 'silicon', 'membranes', '...   \n",
       "...                                                 ...   \n",
       "7021  [['The', 'nanoparticles', '(', 'NPs', ')', 'of...   \n",
       "7022  [['Medication', 'regimen', 'complexity', 'and'...   \n",
       "7023  [['Background', 'There', 'is', 'a', 'relative'...   \n",
       "7024  [['Assessment', 'of', 'periodontal', 'bone', '...   \n",
       "7025  [['The', 'accuracy', 'of', 'analogue', 'and', ...   \n",
       "\n",
       "                              tokenized_words_processed  \n",
       "0     ['dctn4', 'modifi', 'chronic', 'pseudomona', '...  \n",
       "1     ['pseudomona', 'aeruginosa', 'infect', 'cystic...  \n",
       "2     ['nonylphenol', 'diethoxyl', 'inhibit', 'apopt...  \n",
       "3     ['nonylphenol', 'nonylphenol', 'ethoxyl', 'np2...  \n",
       "4     ['prevascular', 'silicon', 'membran', 'enhanc'...  \n",
       "...                                                 ...  \n",
       "7021  ['nanoparticl', 'np', 'hemoglobin', 'hb', 'pre...  \n",
       "7022  ['medic', 'regimen', 'complex', 'preval', 'pot...  \n",
       "7023  ['background', 'rel', 'pauciti', 'inform', 'ch...  \n",
       "7024  ['assess', 'periodont', 'bone', 'level', 'revi...  \n",
       "7025  ['accuraci', 'analogu', 'especi', 'digit', 'ra...  \n",
       "\n",
       "[7026 rows x 6 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without stemming and stowords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_content_train = train_data.groupby(by = ['PMID'])['Content'].agg(lambda x: f'{x.values[0]}. {x.values[1]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88ba28277a1630fc5f744f385ba08b8a5477e64ab64787e3b7b12637e39579c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
