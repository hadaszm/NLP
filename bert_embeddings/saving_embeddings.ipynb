{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krystian.kurek\\miniconda3\\envs\\imagesequenceclassification\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 440M/440M [02:59<00:00, 2.45MB/s]\n",
      "c:\\users\\krystian.kurek\\miniconda3\\envs\\imagesequenceclassification\\lib\\site-packages\\huggingface_hub\\file_download.py:125: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\krystian.kurek\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForPreTraining, BertModel\n",
    "import torch\n",
    "my_sentence = \"Whatever your sentence is\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_embeddings(my_sentence, model=model): \n",
    "    input_ids = tokenizer(my_sentence, return_tensors=\"pt\")\n",
    "    output = model(**input_ids)\n",
    "\n",
    "    final_layer = output.last_hidden_state\n",
    "    return final_layer[0][1].detach().numpy().reshape(1, -1)\n",
    "return_embedings('Whatever').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_extracted_keywords_file(filename): \n",
    "    df = pd.read_csv(filename)\\\n",
    "        .drop('Unnamed: 0', axis=1)\n",
    "    df['topic_keywords'] = df['topic_keywords'].apply(eval)\n",
    "    df = df.explode('topic_keywords')\n",
    "    df[['topic_keyword', 'probability']] = df[['topic_keywords']].apply(lambda x: [x['topic_keywords'][0], x['topic_keywords'][1]], result_type='expand', axis=1)\n",
    "   \n",
    "    df = df.drop('topic_keywords', axis=1)\n",
    "    return df\n",
    "bertopic_keywords = process_extracted_keywords_file('../results/bertopic/bertopic_processed_data_2022-11-22_23-14-24_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>topic_number</th>\n",
       "      <th>topic_probs</th>\n",
       "      <th>topic_keyword</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25763772</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>0.108995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25763772</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>antimicrobi</td>\n",
       "      <td>0.060756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25763772</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>isol</td>\n",
       "      <td>0.059366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25763772</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hmkp</td>\n",
       "      <td>0.049176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25763772</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>infect</td>\n",
       "      <td>0.048220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID  topic_number  topic_probs topic_keyword  probability\n",
       "0  25763772            52          1.0     pneumonia     0.108995\n",
       "0  25763772            52          1.0   antimicrobi     0.060756\n",
       "0  25763772            52          1.0          isol     0.059366\n",
       "0  25763772            52          1.0          hmkp     0.049176\n",
       "0  25763772            52          1.0        infect     0.048220"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertopic_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 494/494 [00:28<00:00, 17.49it/s]\n"
     ]
    }
   ],
   "source": [
    "def return_embeddings_for_keywords(keywords, model=model):\n",
    "    unique_keywords = keywords.drop_duplicates()\n",
    "    embeddings = []\n",
    "    for keyword in tqdm.tqdm(unique_keywords['topic_keyword']): \n",
    "        embeddings.append(return_embeddings(keyword))\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    embeddings = pd.DataFrame(embeddings, columns=list(range(embeddings.shape[1])))\n",
    "    embeddings['topic_keyword'] = unique_keywords['topic_keyword'].reset_index(drop=True)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def add_embeddings_to_keywords(df, model=model): \n",
    "    keywords_embeddings = return_embeddings_for_keywords(df[['topic_keyword']])\n",
    "    return df.merge(keywords_embeddings)\n",
    "\n",
    "bertopic_keywords = add_embeddings_to_keywords(bertopic_keywords, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>topic_number</th>\n",
       "      <th>topic_probs</th>\n",
       "      <th>topic_keyword</th>\n",
       "      <th>probability</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25763772</td>\n",
       "      <td>52</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>0.108995</td>\n",
       "      <td>-0.194289</td>\n",
       "      <td>-0.255824</td>\n",
       "      <td>-0.134394</td>\n",
       "      <td>-0.148016</td>\n",
       "      <td>0.060968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801799</td>\n",
       "      <td>-0.046112</td>\n",
       "      <td>0.462496</td>\n",
       "      <td>0.336230</td>\n",
       "      <td>0.147135</td>\n",
       "      <td>-0.449673</td>\n",
       "      <td>-0.159336</td>\n",
       "      <td>0.183655</td>\n",
       "      <td>0.092611</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27334470</td>\n",
       "      <td>52</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>0.108995</td>\n",
       "      <td>-0.194289</td>\n",
       "      <td>-0.255824</td>\n",
       "      <td>-0.134394</td>\n",
       "      <td>-0.148016</td>\n",
       "      <td>0.060968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801799</td>\n",
       "      <td>-0.046112</td>\n",
       "      <td>0.462496</td>\n",
       "      <td>0.336230</td>\n",
       "      <td>0.147135</td>\n",
       "      <td>-0.449673</td>\n",
       "      <td>-0.159336</td>\n",
       "      <td>0.183655</td>\n",
       "      <td>0.092611</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27346336</td>\n",
       "      <td>52</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>0.108995</td>\n",
       "      <td>-0.194289</td>\n",
       "      <td>-0.255824</td>\n",
       "      <td>-0.134394</td>\n",
       "      <td>-0.148016</td>\n",
       "      <td>0.060968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801799</td>\n",
       "      <td>-0.046112</td>\n",
       "      <td>0.462496</td>\n",
       "      <td>0.336230</td>\n",
       "      <td>0.147135</td>\n",
       "      <td>-0.449673</td>\n",
       "      <td>-0.159336</td>\n",
       "      <td>0.183655</td>\n",
       "      <td>0.092611</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27641480</td>\n",
       "      <td>52</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>0.108995</td>\n",
       "      <td>-0.194289</td>\n",
       "      <td>-0.255824</td>\n",
       "      <td>-0.134394</td>\n",
       "      <td>-0.148016</td>\n",
       "      <td>0.060968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801799</td>\n",
       "      <td>-0.046112</td>\n",
       "      <td>0.462496</td>\n",
       "      <td>0.336230</td>\n",
       "      <td>0.147135</td>\n",
       "      <td>-0.449673</td>\n",
       "      <td>-0.159336</td>\n",
       "      <td>0.183655</td>\n",
       "      <td>0.092611</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27798219</td>\n",
       "      <td>52</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>0.108995</td>\n",
       "      <td>-0.194289</td>\n",
       "      <td>-0.255824</td>\n",
       "      <td>-0.134394</td>\n",
       "      <td>-0.148016</td>\n",
       "      <td>0.060968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801799</td>\n",
       "      <td>-0.046112</td>\n",
       "      <td>0.462496</td>\n",
       "      <td>0.336230</td>\n",
       "      <td>0.147135</td>\n",
       "      <td>-0.449673</td>\n",
       "      <td>-0.159336</td>\n",
       "      <td>0.183655</td>\n",
       "      <td>0.092611</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35125</th>\n",
       "      <td>28295933</td>\n",
       "      <td>47</td>\n",
       "      <td>0.901133</td>\n",
       "      <td>gg</td>\n",
       "      <td>0.029372</td>\n",
       "      <td>-0.728101</td>\n",
       "      <td>-0.560432</td>\n",
       "      <td>0.696359</td>\n",
       "      <td>-0.845489</td>\n",
       "      <td>-0.546084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292864</td>\n",
       "      <td>0.023463</td>\n",
       "      <td>0.890567</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.290927</td>\n",
       "      <td>-0.135723</td>\n",
       "      <td>-0.090461</td>\n",
       "      <td>0.051818</td>\n",
       "      <td>0.370925</td>\n",
       "      <td>0.745343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35126</th>\n",
       "      <td>28359307</td>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gg</td>\n",
       "      <td>0.029372</td>\n",
       "      <td>-0.728101</td>\n",
       "      <td>-0.560432</td>\n",
       "      <td>0.696359</td>\n",
       "      <td>-0.845489</td>\n",
       "      <td>-0.546084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292864</td>\n",
       "      <td>0.023463</td>\n",
       "      <td>0.890567</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.290927</td>\n",
       "      <td>-0.135723</td>\n",
       "      <td>-0.090461</td>\n",
       "      <td>0.051818</td>\n",
       "      <td>0.370925</td>\n",
       "      <td>0.745343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35127</th>\n",
       "      <td>28470753</td>\n",
       "      <td>47</td>\n",
       "      <td>0.878475</td>\n",
       "      <td>gg</td>\n",
       "      <td>0.029372</td>\n",
       "      <td>-0.728101</td>\n",
       "      <td>-0.560432</td>\n",
       "      <td>0.696359</td>\n",
       "      <td>-0.845489</td>\n",
       "      <td>-0.546084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292864</td>\n",
       "      <td>0.023463</td>\n",
       "      <td>0.890567</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.290927</td>\n",
       "      <td>-0.135723</td>\n",
       "      <td>-0.090461</td>\n",
       "      <td>0.051818</td>\n",
       "      <td>0.370925</td>\n",
       "      <td>0.745343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35128</th>\n",
       "      <td>28522288</td>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gg</td>\n",
       "      <td>0.029372</td>\n",
       "      <td>-0.728101</td>\n",
       "      <td>-0.560432</td>\n",
       "      <td>0.696359</td>\n",
       "      <td>-0.845489</td>\n",
       "      <td>-0.546084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292864</td>\n",
       "      <td>0.023463</td>\n",
       "      <td>0.890567</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.290927</td>\n",
       "      <td>-0.135723</td>\n",
       "      <td>-0.090461</td>\n",
       "      <td>0.051818</td>\n",
       "      <td>0.370925</td>\n",
       "      <td>0.745343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35129</th>\n",
       "      <td>28527621</td>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gg</td>\n",
       "      <td>0.029372</td>\n",
       "      <td>-0.728101</td>\n",
       "      <td>-0.560432</td>\n",
       "      <td>0.696359</td>\n",
       "      <td>-0.845489</td>\n",
       "      <td>-0.546084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292864</td>\n",
       "      <td>0.023463</td>\n",
       "      <td>0.890567</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>-0.290927</td>\n",
       "      <td>-0.135723</td>\n",
       "      <td>-0.090461</td>\n",
       "      <td>0.051818</td>\n",
       "      <td>0.370925</td>\n",
       "      <td>0.745343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35130 rows × 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PMID  topic_number  topic_probs topic_keyword  probability  \\\n",
       "0      25763772            52     1.000000     pneumonia     0.108995   \n",
       "1      27334470            52     1.000000     pneumonia     0.108995   \n",
       "2      27346336            52     1.000000     pneumonia     0.108995   \n",
       "3      27641480            52     1.000000     pneumonia     0.108995   \n",
       "4      27798219            52     1.000000     pneumonia     0.108995   \n",
       "...         ...           ...          ...           ...          ...   \n",
       "35125  28295933            47     0.901133            gg     0.029372   \n",
       "35126  28359307            47     1.000000            gg     0.029372   \n",
       "35127  28470753            47     0.878475            gg     0.029372   \n",
       "35128  28522288            47     1.000000            gg     0.029372   \n",
       "35129  28527621            47     1.000000            gg     0.029372   \n",
       "\n",
       "              0         1         2         3         4  ...       758  \\\n",
       "0     -0.194289 -0.255824 -0.134394 -0.148016  0.060968  ...  0.801799   \n",
       "1     -0.194289 -0.255824 -0.134394 -0.148016  0.060968  ...  0.801799   \n",
       "2     -0.194289 -0.255824 -0.134394 -0.148016  0.060968  ...  0.801799   \n",
       "3     -0.194289 -0.255824 -0.134394 -0.148016  0.060968  ...  0.801799   \n",
       "4     -0.194289 -0.255824 -0.134394 -0.148016  0.060968  ...  0.801799   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "35125 -0.728101 -0.560432  0.696359 -0.845489 -0.546084  ...  0.292864   \n",
       "35126 -0.728101 -0.560432  0.696359 -0.845489 -0.546084  ...  0.292864   \n",
       "35127 -0.728101 -0.560432  0.696359 -0.845489 -0.546084  ...  0.292864   \n",
       "35128 -0.728101 -0.560432  0.696359 -0.845489 -0.546084  ...  0.292864   \n",
       "35129 -0.728101 -0.560432  0.696359 -0.845489 -0.546084  ...  0.292864   \n",
       "\n",
       "            759       760       761       762       763       764       765  \\\n",
       "0     -0.046112  0.462496  0.336230  0.147135 -0.449673 -0.159336  0.183655   \n",
       "1     -0.046112  0.462496  0.336230  0.147135 -0.449673 -0.159336  0.183655   \n",
       "2     -0.046112  0.462496  0.336230  0.147135 -0.449673 -0.159336  0.183655   \n",
       "3     -0.046112  0.462496  0.336230  0.147135 -0.449673 -0.159336  0.183655   \n",
       "4     -0.046112  0.462496  0.336230  0.147135 -0.449673 -0.159336  0.183655   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "35125  0.023463  0.890567 -0.099152 -0.290927 -0.135723 -0.090461  0.051818   \n",
       "35126  0.023463  0.890567 -0.099152 -0.290927 -0.135723 -0.090461  0.051818   \n",
       "35127  0.023463  0.890567 -0.099152 -0.290927 -0.135723 -0.090461  0.051818   \n",
       "35128  0.023463  0.890567 -0.099152 -0.290927 -0.135723 -0.090461  0.051818   \n",
       "35129  0.023463  0.890567 -0.099152 -0.290927 -0.135723 -0.090461  0.051818   \n",
       "\n",
       "            766       767  \n",
       "0      0.092611  0.061448  \n",
       "1      0.092611  0.061448  \n",
       "2      0.092611  0.061448  \n",
       "3      0.092611  0.061448  \n",
       "4      0.092611  0.061448  \n",
       "...         ...       ...  \n",
       "35125  0.370925  0.745343  \n",
       "35126  0.370925  0.745343  \n",
       "35127  0.370925  0.745343  \n",
       "35128  0.370925  0.745343  \n",
       "35129  0.370925  0.745343  \n",
       "\n",
       "[35130 rows x 773 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertopic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
